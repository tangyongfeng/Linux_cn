<!DOCTYPE html>
<html lang="zh">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>Kubernetes 分布式应用部署实战：以人脸识别应用为例</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="Author: Hannibal 简介 伙计们，请搬好小板凳坐好，下面将是一段漫长的旅程，期望你能够乐在其中。 我将基于 Kubernetes 部署一个分布式应用。我 …" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">linux_cn</a></h1>
                <nav><ul>
                    <li><a href="/category/chuan-shan-jia-zhuan-fang">穿山甲专访</a></li>
                    <li><a href="/category/dai-ma-ying-xiong">代码英雄</a></li>
                    <li><a href="/category/fen-xiang">分享</a></li>
                    <li><a href="/category/guan-dian">观点</a></li>
                    <li><a href="/category/huo-dong">活动</a></li>
                    <li><a href="/category/ji-ke-man-hua">极客漫画</a></li>
                    <li class="active"><a href="/category/ji-zhu">技术</a></li>
                    <li><a href="/category/kai-yuan-zhi-hui">开源智慧</a></li>
                    <li><a href="/category/linux-fa-xing-ban">Linux 发行版</a></li>
                    <li><a href="/category/mei-ri-an-quan-zi-xun">每日安全资讯</a></li>
                    <li><a href="/category/misc">Misc</a></li>
                    <li><a href="/category/qu-kuai-lian">区块链</a></li>
                    <li><a href="/category/rong-qi-yu-yun">容器与云</a></li>
                    <li><a href="/category/ruan-jian-kai-fa">软件开发</a></li>
                    <li><a href="/category/shu-mei-pai">树莓派</a></li>
                    <li><a href="/category/xi-tong-yun-wei">系统运维</a></li>
                    <li><a href="/category/xin-wen">新闻</a></li>
                    <li><a href="/category/ying-he-guan-cha">硬核观察</a></li>
                    <li><a href="/category/zhi-ye-sheng-ya">职业生涯</a></li>
                    <li><a href="/category/zhong-jiang-ming-dan">中奖名单</a></li>
                    <li><a href="/category/zhuo-mian-ying-yong">桌面应用</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/2018/07/kubernetes-fen-bu-shi-ying-yong-bu-shu-shi-zhan-yi-ren-lian-shi-bie-ying-yong-wei-li.html" rel="bookmark"
           title="Permalink to Kubernetes 分布式应用部署实战：以人脸识别应用为例">Kubernetes 分布式应用部署实战：以人脸识别应用为例</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-07-30T18:24:55+02:00">
                Published: Mon 30 July 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/linux-fans-from-china.html">linux fans from china</a>
        </address>
<p>In <a href="/category/ji-zhu">技术</a>.</p>

</footer><!-- /.post-info -->      <p>Author: Hannibal</p>
<p><img alt="" src="/data/attachment/album/201807/30/182100utggq5s2nlwyxzsl.jpg"></p>
<h2>简介</h2>
<p>伙计们，请搬好小板凳坐好，下面将是一段漫长的旅程，期望你能够乐在其中。</p>
<p>我将基于 <a href="https://kubernetes.io/">Kubernetes</a> 部署一个分布式应用。我曾试图编写一个尽可能真实的应用，但由于时间和精力有限，最终砍掉了很多细节。</p>
<p>我将聚焦 Kubernetes 及其部署。</p>
<p>让我们开始吧。</p>
<h2>应用</h2>
<h3>TL;DR</h3>
<p><img alt="" src="/data/attachment/album/201807/30/182110rjm2ufth3k7kdtky.jpg"></p>
<p>该应用本身由 6 个组件构成。代码可以从如下链接中找到：<a href="https://github.com/Skarlso/kube-cluster-sample">Kubenetes 集群示例</a>。</p>
<p>这是一个人脸识别服务，通过比较已知个人的图片，识别给定图片对应的个人。前端页面用表格形式简要的展示图片及对应的个人。具体而言，向 <a href="https://github.com/Skarlso/kube-cluster-sample">接收器</a> 发送请求，请求包含指向一个图片的链接。图片可以位于任何位置。接受器将图片地址存储到数据库 (MySQL) 中，然后向队列发送处理请求，请求中包含已保存图片的 ID。这里我们使用 <a href="http://nsq.io/">NSQ</a> 建立队列。</p>
<p><a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/image_processor">图片处理</a> 服务一直监听处理请求队列，从中获取任务。处理过程包括如下几步：获取图片 ID，读取图片，通过 <a href="https://grpc.io/">gRPC</a> 将图片路径发送至 Python 编写的 <a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/face_recognition">人脸识别</a> 后端。如果识别成功，后端给出图片对应个人的名字。图片处理器进而根据个人 ID 更新图片记录，将其标记为处理成功。如果识别不成功，图片被标记为待解决。如果图片识别过程中出现错误，图片被标记为失败。</p>
<p>标记为失败的图片可以通过计划任务等方式进行重试。</p>
<p>那么具体是如何工作的呢？我们深入探索一下。</p>
<h3>接收器</h3>
<p>接收器服务是整个流程的起点，通过如下形式的 API 接收请求：</p>
<div class="highlight"><pre><span></span><code>curl -d &#39;{&quot;path&quot;:&quot;/unknown_images/unknown0001.jpg&quot;}&#39; http://127.0.0.1:8000/image/post
</code></pre></div>

<p>此时，接收器将<ruby> 路径 <rt>  path </rt></ruby>存储到共享数据库集群中，该实体存储后将从数据库服务收到对应的 ID。本应用采用“<ruby> 实体对象 <rt>  Entity Object </rt></ruby>的唯一标识由持久层提供”的模型。获得实体 ID 后，接收器向 NSQ 发送消息，至此接收器的工作完成。</p>
<h3>图片处理器</h3>
<p>从这里开始变得有趣起来。图片处理器首次运行时会创建两个 Go <ruby> 协程 <rt>  routine </rt></ruby>，具体为：</p>
<h3>Consume</h3>
<p>这是一个 NSQ 消费者，需要完成三项必需的任务。首先，监听队列中的消息。其次，当有新消息到达时，将对应的 ID 追加到一个线程安全的 ID 片段中，以供第二个协程处理。最后，告知第二个协程处理新任务，方法为 <a href="https://golang.org/pkg/sync/#Cond">sync.Condition</a>。</p>
<h3>ProcessImages</h3>
<p>该协程会处理指定 ID 片段，直到对应片段全部处理完成。当处理完一个片段后，该协程并不是在一个通道上睡眠等待，而是进入悬挂状态。对每个 ID，按如下步骤顺序处理：</p>
<ul>
<li>与人脸识别服务建立 gRPC 连接，其中人脸识别服务会在人脸识别部分进行介绍</li>
<li>从数据库获取图片对应的实体</li>
<li>为 <a href="https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/#circuit-breaker">断路器</a> 准备两个函数<ul>
<li>函数 1: 用于 RPC 方法调用的主函数</li>
<li>函数 2: 基于 ping 的断路器健康检查</li>
</ul>
</li>
<li>调用函数 1 将图片路径发送至人脸识别服务，其中路径应该是人脸识别服务可以访问的，最好是共享的，例如 NFS</li>
<li>如果调用失败，将图片实体状态更新为 FAILEDPROCESSING</li>
<li>如果调用成功，返回值是一个图片的名字，对应数据库中的一个个人。通过联合 SQL 查询，获取对应个人的 ID</li>
<li>将数据库中的图片实体状态更新为 PROCESSED，更新图片被识别成的个人的 ID</li>
</ul>
<p>这个服务可以复制多份同时运行。</p>
<h3>断路器</h3>
<p>即使对于一个复制资源几乎没有开销的系统，也会有意外的情况发生，例如网络故障或任何两个服务之间的通信存在问题等。我在 gRPC 调用中实现了一个简单的断路器，这十分有趣。</p>
<p>下面给出工作原理：</p>
<p><img alt="" src="/data/attachment/album/201807/30/182155wue0igyuwuws9iss.jpg"></p>
<p>当出现 5 次不成功的服务调用时，断路器启动并阻断后续的调用请求。经过指定的时间后，它对服务进行健康检查并判断是否恢复。如果问题依然存在，等待时间会进一步增大。如果已经恢复，断路器停止对服务调用的阻断，允许请求流量通过。</p>
<h3>前端</h3>
<p>前端只包含一个极其简单的表格视图，通过 Go 自身的 html/模板显示一系列图片。</p>
<h3>人脸识别</h3>
<p>人脸识别是整个识别的关键点。仅因为追求灵活性，我将这个服务设计为基于 gRPC 的服务。最初我使用 Go 编写，但后续发现基于 Python 的实现更加适合。事实上，不算 gRPC 部分的代码，人脸识别部分仅有 7 行代码。我使用的<a href="https://github.com/ageitgey/face_recognition">人脸识别</a>库极为出色，它包含 OpenCV 的全部 C 绑定。维护 API 标准意味着只要标准本身不变，实现可以任意改变。</p>
<p>注意：我曾经试图使用 <a href="https://gocv.io/">GoCV</a>，这是一个极好的 Go 库，但欠缺所需的 C 绑定。推荐马上了解一下这个库，它会让你大吃一惊，例如编写若干行代码即可实现实时摄像处理。</p>
<p>这个 Python 库的工作方式本质上很简单。准备一些你认识的人的图片，把信息记录下来。对于我而言，我有一个图片文件夹，包含若干图片，名称分别为 <code>hannibal_1.jpg</code>、 <code>hannibal_2.jpg</code>、 <code>gergely_1.jpg</code>、 <code>john_doe.jpg</code>。在数据库中，我使用两个表记录信息，分别为 <code>person</code>、 <code>person_images</code>，具体如下：</p>
<div class="highlight"><pre><span></span><code><span class="nb">+----+----------+</span>
<span class="c">| id | name     |</span>
<span class="nb">+----+----------+</span>
<span class="c">|  1 | Gergely  |</span>
<span class="c">|  2 | John Doe |</span>
<span class="c">|  3 | Hannibal |</span>
<span class="nb">+----+----------+</span>
<span class="nb">+----+----------------+-----------+</span>
<span class="c">| id | image_name     | person_id |</span>
<span class="nb">+----+----------------+-----------+</span>
<span class="c">|  1 | hannibal_1</span><span class="nt">.</span><span class="c">jpg |         3 |</span>
<span class="c">|  2 | hannibal_2</span><span class="nt">.</span><span class="c">jpg |         3 |</span>
<span class="nb">+----+----------------+-----------+</span>
</code></pre></div>

<p>人脸识别库识别出未知图片后，返回图片的名字。我们接着使用类似下面的联合查询找到对应的个人。</p>
<div class="highlight"><pre><span></span><code>select person.name, person.id from person inner join person_images as pi on person.id = pi.person_id where image_name = &#39;hannibal_2.jpg&#39;;
</code></pre></div>

<p>gRPC 调用返回的个人 ID 用于更新图片的 <code>person</code> 列。</p>
<h3>NSQ</h3>
<p>NSQ 是 Go 编写的小规模队列，可扩展且占用系统内存较少。NSQ 包含一个查询服务，用于消费者接收消息；包含一个守护进程，用于发送消息。</p>
<p>在 NSQ 的设计理念中，消息发送程序应该与守护进程在同一台主机上，故发送程序仅需发送至 localhost。但守护进程与查询服务相连接，这使其构成了全局队列。</p>
<p>这意味着有多少 NSQ 守护进程就有多少对应的发送程序。但由于其资源消耗极小，不会影响主程序的资源使用。</p>
<h3>配置</h3>
<p>为了尽可能增加灵活性以及使用 Kubernetes 的 ConfigSet 特性，我在开发过程中使用 <code>.env</code> 文件记录配置信息，例如数据库服务的地址以及 NSQ 的查询地址。在生产环境或 Kubernetes 环境中，我将使用环境变量属性配置。</p>
<h3>应用小结</h3>
<p>这就是待部署应用的全部架构信息。应用的各个组件都是可变更的，他们之间仅通过数据库、消息队列和 gRPC 进行耦合。考虑到更新机制的原理，这是部署分布式应用所必须的；在部署部分我会继续分析。</p>
<h2>使用 Kubernetes 部署应用</h2>
<h3>基础知识</h3>
<p>Kubernetes 是什么？</p>
<p>这里我会提到一些基础知识，但不会深入细节，细节可以用一本书的篇幅描述，例如 <a href="http://shop.oreilly.com/product/0636920043874.do">Kubernetes 构建与运行</a>。另外，如果你愿意挑战自己，可以查看官方文档：<a href="https://kubernetes.io/docs/">Kubernetes 文档</a>。</p>
<p>Kubernetes 是容器化服务及应用的管理器。它易于扩展，可以管理大量容器；更重要的是，可以通过基于 yaml 的模板文件高度灵活地进行配置。人们经常把 Kubernetes 比作 Docker Swarm，但 Kubernetes 的功能不仅仅如此。例如，Kubernetes 不关心底层容器实现，你可以使用 LXC 与 Kubernetes 的组合，效果与使用 Docker 一样好。Kubernetes 在管理容器的基础上，可以管理已部署的服务或应用集群。如何操作呢？让我们概览一下用于构成 Kubernetes 的模块。</p>
<p>在 Kubernetes 中，你给出期望的应用状态，Kubernetes 会尽其所能达到对应的状态。状态可以是已部署、已暂停，有 2 个副本等，以此类推。</p>
<p>Kubernetes 使用标签和注释标记组件，包括服务、部署、副本组、守护进程组等在内的全部组件都被标记。考虑如下场景，为了识别 pod 与应用的对应关系，使用 <code>app: myapp</code> 标签。假设应用已部署 2 个容器，如果你移除其中一个容器的 <code>app</code> 标签，Kubernetes 只能识别到一个容器（隶属于应用），进而启动一个新的具有 <code>myapp</code> 标签的实例。</p>
<h3>Kubernetes 集群</h3>
<p>要使用 Kubernetes，需要先搭建一个 Kubernetes 集群。搭建 Kubernetes 集群可能是一个痛苦的经历，但所幸有工具可以帮助我们。Minikube 为我们在本地搭建一个单节点集群。AWS 的一个 beta 服务工作方式类似于 Kubernetes 集群，你只需请求节点并定义你的部署即可。Kubernetes 集群组件的文档如下：<a href="https://kubernetes.io/docs/concepts/overview/components/">Kubernetes 集群组件</a>。</p>
<h3>节点</h3>
<p><ruby> 节点 <rt>  node </rt></ruby>是工作单位，形式可以是虚拟机、物理机，也可以是各种类型的云主机。</p>
<h3>Pod</h3>
<p>Pod 是本地容器逻辑上组成的集合，即一个 Pod 中可能包含若干个容器。Pod 创建后具有自己的 DNS 和虚拟 IP，这样 Kubernetes 可以对到达流量进行负载均衡。你几乎不需要直接和容器打交道；即使是调试的时候，例如查看日志，你通常调用 <code>kubectl logs deployment/your-app -f</code> 查看部署日志，而不是使用 <code>-c container_name</code> 查看具体某个容器的日志。<code>-f</code> 参数表示从日志尾部进行流式输出。</p>
<h3>部署</h3>
<p>在 Kubernetes 中创建任何类型的资源时，后台使用一个<ruby> 部署 <rt>  deployment </rt></ruby>组件，它指定了资源的期望状态。使用部署对象，你可以将 Pod 或服务变更为另外的状态，也可以更新应用或上线新版本应用。你一般不会直接操作副本组 (后续会描述)，而是通过部署对象创建并管理。</p>
<h3>服务</h3>
<p>默认情况下，Pod 会获取一个 IP 地址。但考虑到 Pod 是 Kubernetes 中的易失性组件，我们需要更加持久的组件。不论是队列，MySQL、内部 API 或前端，都需要长期运行并使用保持不变的 IP 或更好的 DNS 记录。</p>
<p>为解决这个问题，Kubernetes 提供了<ruby> 服务 <rt>  service </rt></ruby>组件，可以定义访问模式，支持的模式包括负载均衡、简单 IP 或内部 DNS。</p>
<p>Kubernetes 如何获知服务运行正常呢？你可以配置健康性检查和可用性检查。健康性检查是指检查容器是否处于运行状态，但容器处于运行状态并不意味着服务运行正常。对此，你应该使用可用性检查，即请求应用的一个特别<ruby> 接口 <rt>  endpoint </rt></ruby>。</p>
<p>由于服务非常重要，推荐你找时间阅读以下文档：<a href="https://kubernetes.io/docs/concepts/services-networking/service/">服务</a>。严肃的说，需要阅读的东西很多，有 24 页 A4 纸的篇幅，涉及网络、服务及自动发现。这也有助于你决定是否真的打算在生产环境中使用 Kubernetes。</p>
<h3>DNS / 服务发现</h3>
<p>在 Kubernetes 集群中创建服务后，该服务会从名为 <code>kube-proxy</code> 和 <code>kube-dns</code> 的特殊 Kubernetes 部署中获取一个 DNS 记录。它们两个用于提供集群内的服务发现。如果你有一个正在运行的 MySQL 服务并配置 <code>clusterIP: no</code>，那么集群内部任何人都可以通过 <code>mysql.default.svc.cluster.local</code> 访问该服务，其中：</p>
<ul>
<li><code>mysql</code> – 服务的名称</li>
<li><code>default</code> – 命名空间的名称</li>
<li><code>svc</code> – 对应服务分类</li>
<li><code>cluster.local</code> – 本地集群的域名</li>
</ul>
<p>可以使用自定义设置更改本地集群的域名。如果想让服务可以从集群外访问，需要使用 DNS 服务，并使用例如 Nginx 将 IP 地址绑定至记录。服务对应的对外 IP 地址可以使用如下命令查询：</p>
<ul>
<li>节点端口方式 – <code>kubectl get -o jsonpath="{.spec.ports[0].nodePort}" services mysql</code></li>
<li>负载均衡方式 – <code>kubectl get -o jsonpath="{.spec.ports[0].LoadBalancer}" services mysql</code></li>
</ul>
<h3>模板文件</h3>
<p>类似 Docker Compose、TerraForm 或其它的服务管理工具，Kubernetes 也提供了基础设施描述模板。这意味着，你几乎不用手动操作。</p>
<p>以 Nginx 部署为例，查看下面的 yaml 模板：</p>
<div class="highlight"><pre><span></span><code><span class="n">apiVersion</span><span class="o">:</span><span class="w"> </span><span class="n">apps</span><span class="o">/</span><span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span><span class="w"> </span><span class="n">Deployment</span><span class="w"> </span><span class="err">#</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="n">metadata</span><span class="o">:</span><span class="w"> </span><span class="err">#</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="w">  </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">nginx</span><span class="o">-</span><span class="n">deployment</span>
<span class="w">  </span><span class="n">labels</span><span class="o">:</span><span class="w"> </span><span class="err">#</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
<span class="w">    </span><span class="n">app</span><span class="o">:</span><span class="w"> </span><span class="n">nginx</span>
<span class="n">spec</span><span class="o">:</span><span class="w"> </span><span class="err">#</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
<span class="w">  </span><span class="n">replicas</span><span class="o">:</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="err">#</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="w">  </span><span class="n">selector</span><span class="o">:</span>
<span class="w">    </span><span class="n">matchLabels</span><span class="o">:</span>
<span class="w">      </span><span class="n">app</span><span class="o">:</span><span class="w"> </span><span class="n">nginx</span>
<span class="w">  </span><span class="n">template</span><span class="o">:</span>
<span class="w">    </span><span class="n">metadata</span><span class="o">:</span>
<span class="w">      </span><span class="n">labels</span><span class="o">:</span>
<span class="w">        </span><span class="n">app</span><span class="o">:</span><span class="w"> </span><span class="n">nginx</span>
<span class="w">    </span><span class="n">spec</span><span class="o">:</span>
<span class="w">      </span><span class="n">containers</span><span class="o">:</span><span class="w"> </span><span class="err">#</span><span class="o">(</span><span class="mi">6</span><span class="o">)</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">nginx</span>
<span class="w">        </span><span class="n">image</span><span class="o">:</span><span class="w"> </span><span class="n">nginx</span><span class="o">:</span><span class="mf">1.7</span><span class="o">.</span><span class="mi">9</span>
<span class="w">        </span><span class="n">ports</span><span class="o">:</span>
<span class="w">        </span><span class="o">-</span><span class="w"> </span><span class="n">containerPort</span><span class="o">:</span><span class="w"> </span><span class="mi">80</span>
</code></pre></div>

<p>在这个示例部署中，我们做了如下操作：</p>
<ul>
<li>(1) 使用 <code>kind</code> 关键字定义模板类型</li>
<li>(2) 使用 <code>metadata</code> 关键字，增加该部署的识别信息</li>
<li>(3) 使用 <code>labels</code> 标记每个需要创建的资源</li>
<li>(4) 然后使用 <code>spec</code> 关键字描述所需的状态</li>
<li>(5) nginx 应用需要 3 个副本</li>
<li>(6) Pod 中容器的模板定义部分</li>
<li>容器名称为 nginx</li>
<li>容器模板为 nginx:1.7.9 （本例使用 Docker 镜像）</li>
</ul>
<h3>副本组</h3>
<p><ruby> 副本组 <rt>  ReplicaSet </rt></ruby>是一个底层的副本管理器，用于保证运行正确数目的应用副本。相比而言，部署是更高层级的操作，应该用于管理副本组。除非你遇到特殊的情况，需要控制副本的特性，否则你几乎不需要直接操作副本组。</p>
<h3>守护进程组</h3>
<p>上面提到 Kubernetes 始终使用标签，还有印象吗？<ruby> 守护进程组 <rt>  DaemonSet </rt></ruby>是一个控制器，用于确保守护进程化的应用一直运行在具有特定标签的节点中。</p>
<p>例如，你将所有节点增加 <code>logger</code> 或 <code>mission_critical</code> 的标签，以便运行日志 / 审计服务的守护进程。接着，你创建一个守护进程组并使用 <code>logger</code> 或 <code>mission_critical</code> 节点选择器。Kubernetes 会查找具有该标签的节点，确保守护进程的实例一直运行在这些节点中。因而，节点中运行的所有进程都可以在节点内访问对应的守护进程。</p>
<p>以我的应用为例，NSQ 守护进程可以用守护进程组实现。具体而言，将对应节点增加 <code>recevier</code> 标签，创建一个守护进程组并配置 <code>receiver</code> 应用选择器，这样这些节点上就会一直运行接收者组件。</p>
<p>守护进程组具有副本组的全部优势，可扩展且由 Kubernetes 管理，意味着 Kubernetes 管理其全生命周期的事件，确保持续运行，即使出现故障，也会立即替换。</p>
<h3>扩展</h3>
<p>在 Kubernetes 中，扩展是稀松平常的事情。副本组负责 Pod 运行的实例数目。就像你在 nginx 部署那个示例中看到的那样，对应设置项 <code>replicas:3</code>。我们可以按应用所需，让 Kubernetes 运行多份应用副本。</p>
<p>当然，设置项有很多。你可以指定让多个副本运行在不同的节点上，也可以指定各种不同的应用启动等待时间。想要在这方面了解更多，可以阅读 <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">水平扩展</a> 和 <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/scale-interactive/">Kubernetes 中的交互式扩展</a>；当然 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">副本组</a> 的细节对你也有帮助，毕竟 Kubernetes 中的扩展功能都来自于该模块。</p>
<h3>Kubernetes 部分小结</h3>
<p>Kubernetes 是容器编排的便捷工具，工作单元为 Pod，具有分层架构。最顶层是部署，用于操作其它资源，具有高度可配置性。对于你的每个命令调用，Kubernetes 提供了对应的 API，故理论上你可以编写自己的代码，向 Kubernetes API 发送数据，得到与 <code>kubectl</code> 命令同样的效果。</p>
<p>截至目前，Kubernetes 原生支持所有主流云服务供应商，而且完全开源。如果你愿意，可以贡献代码；如果你希望对工作原理有深入了解，可以查阅代码：<a href="https://github.com/kubernetes/kubernetes">GitHub 上的 Kubernetes 项目</a>。</p>
<h3>Minikube</h3>
<p>接下来我会使用 <a href="https://github.com/kubernetes/minikube/">Minikube</a> 这款本地 Kubernetes 集群模拟器。它并不擅长模拟多节点集群，但可以很容易地给你提供本地学习环境，让你开始探索，这很棒。Minikube 基于可高度调优的虚拟机，由 VirtualBox 类似的虚拟化工具提供。</p>
<p>我用到的全部 Kubernetes 模板文件可以在这里找到：<a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/kube_files">Kubernetes 文件</a>。</p>
<p>注意：在你后续测试可扩展性时，会发现副本一直处于 <code>Pending</code> 状态，这是因为 minikube 集群中只有一个节点，不应该允许多副本运行在同一个节点上，否则明显只是耗尽了可用资源。使用如下命令可以查看可用资源：</p>
<div class="highlight"><pre><span></span><code>kubectl get nodes -o yaml
</code></pre></div>

<h3>构建容器</h3>
<p>Kubernetes 支持大多数现有的容器技术。我这里使用 Docker。每一个构建的服务容器，对应代码库中的一个 Dockerfile 文件。我推荐你仔细阅读它们，其中大多数都比较简单。对于 Go 服务，我采用了最近引入的多步构建的方式。Go 服务基于 Alpine Linux 镜像创建。人脸识别程序使用 Python、NSQ 和 MySQL 使用对应的容器。</p>
<h3>上下文</h3>
<p>Kubernetes 使用命名空间。如果你不额外指定命名空间，Kubernetes 会使用 <code>default</code> 命名空间。为避免污染默认命名空间，我会一直指定命名空间，具体操作如下：</p>
<div class="highlight"><pre><span></span><code>❯ kubectl config set-context kube-face-cluster --namespace=face
Context &quot;kube-face-cluster&quot; created.
</code></pre></div>

<p>创建上下文之后，应马上启用：</p>
<div class="highlight"><pre><span></span><code>❯ kubectl config use-context kube-face-cluster
Switched to context &quot;kube-face-cluster&quot;.
</code></pre></div>

<p>此后，所有 <code>kubectl</code> 命令都会使用 <code>face</code> 命名空间。</p>
<p>（LCTT 译注：作者后续并没有使用 face 命名空间，模板文件中的命名空间仍为 default，可能 face 命名空间用于开发环境。如果希望使用 face 命令空间，需要将内部 DNS 地址中的 default 改成 face；如果只是测试，可以不执行这两条命令。）</p>
<h2>应用部署</h2>
<p>Pods 和 服务概览:</p>
<p><img alt="" src="/data/attachment/album/201807/30/182244ug3n5n07025e3zlv.jpg"></p>
<h3>MySQL</h3>
<p>第一个要部署的服务是数据库。</p>
<p>按照 Kubernetes 的示例 <a href="https://kubernetes.io/docs/tasks/run-application/run-single-instance-stateful-application/#deploy-mysql">Kubenetes MySQL</a> 进行部署，即可以满足我的需求。注意：示例配置文件的 MYSQL_PASSWORD 字段使用了明文密码，我将使用 <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes Secrets</a> 对象以提高安全性。</p>
<p>我创建了一个 Secret 对象，对应的本地 yaml 文件如下：</p>
<div class="highlight"><pre><span></span><code><span class="n">apiVersion</span><span class="o">:</span><span class="w"> </span><span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span><span class="w"> </span><span class="n">Secret</span>
<span class="n">metadata</span><span class="o">:</span>
<span class="w">  </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">kube</span><span class="o">-</span><span class="n">face</span><span class="o">-</span><span class="n">secret</span>
<span class="n">type</span><span class="o">:</span><span class="w"> </span><span class="n">Opaque</span>
<span class="n">data</span><span class="o">:</span>
<span class="w">  </span><span class="n">mysql_password</span><span class="o">:</span><span class="w"> </span><span class="n">base64codehere</span>
<span class="w">  </span><span class="n">mysql_userpassword</span><span class="o">:</span><span class="w"> </span><span class="n">base64codehere</span>
</code></pre></div>

<p>其中 base64 编码通过如下命令生成：</p>
<div class="highlight"><pre><span></span><code>echo -n &quot;ubersecurepassword&quot; | base64
echo -n &quot;root:ubersecurepassword&quot; | base64
</code></pre></div>

<p>（LCTT 译注：secret yaml 文件中的 data 应该有两条，一条对应 <code>mysql_password</code>，仅包含密码；另一条对应 <code>mysql_userpassword</code>，包含用户和密码。后文会用到 <code>mysql_userpassword</code>，但没有提及相应的生成）</p>
<p>我的部署 yaml 对应部分如下：</p>
<div class="highlight"><pre><span></span><code>...
<span class="k">-</span> name: MYSQL_ROOT_PASSWORD
  valueFrom:
    secretKeyRef:
      name: kube-face-secret
      key: mysql_password
...
</code></pre></div>

<p>另外值得一提的是，我使用卷将数据库持久化，卷对应的定义如下：</p>
<div class="highlight"><pre><span></span><code><span class="o">...</span>
<span class="w">        </span><span class="n">volumeMounts</span><span class="p">:</span>
<span class="w">        </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">mysql</span><span class="o">-</span><span class="n">persistent</span><span class="o">-</span><span class="n">storage</span>
<span class="w">          </span><span class="n">mountPath</span><span class="p">:</span><span class="w"> </span><span class="o">/</span><span class="k">var</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">mysql</span>
<span class="o">...</span>
<span class="w">      </span><span class="n">volumes</span><span class="p">:</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">mysql</span><span class="o">-</span><span class="n">persistent</span><span class="o">-</span><span class="n">storage</span>
<span class="w">        </span><span class="n">persistentVolumeClaim</span><span class="p">:</span>
<span class="w">          </span><span class="n">claimName</span><span class="p">:</span><span class="w"> </span><span class="n">mysql</span><span class="o">-</span><span class="n">pv</span><span class="o">-</span><span class="n">claim</span>
<span class="o">...</span>
</code></pre></div>

<p>其中 <code>presistentVolumeClain</code> 是关键，告知 Kubernetes 当前资源需要持久化存储。持久化存储的提供方式对用户透明。类似 Pods，如果想了解更多细节，参考文档：<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">Kubernetes 持久化存储</a>。</p>
<p>（LCTT 译注：使用 <code>presistentVolumeClain</code> 之前需要创建 <code>presistentVolume</code>，对于单节点可以使用本地存储，对于多节点需要使用共享存储，因为 Pod 可以能调度到任何一个节点）</p>
<p>使用如下命令部署 MySQL 服务：</p>
<div class="highlight"><pre><span></span><code>kubectl apply -f mysql.yaml
</code></pre></div>

<p>这里比较一下 <code>create</code> 和 <code>apply</code>。<code>apply</code> 是一种<ruby> 宣告式 <rt>  declarative </rt></ruby>的对象配置命令，而 <code>create</code> 是<ruby> 命令式 <rt>  imperative </rt> 的命令。当下我们需要知道的是， <code>  create </code> 通常对应一项任务，例如运行某个组件或创建一个部署；相比而言，当我们使用 <code>  apply </code> 的时候，用户并没有指定具体操作，Kubernetes 会根据集群目前的状态定义需要执行的操作。故如果不存在名为 <code>  mysql </code> 的服务，当我执行 <code>  apply -f mysql.yaml </code> 时，Kubernetes 会创建该服务。如果再次执行这个命令，Kubernetes 会忽略该命令。但如果我再次运行 <code>  create </code> ，Kubernetes 会报错，告知服务已经创建。</ruby></p>
<p>想了解更多信息，请阅读如下文档：<a href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/overview/">Kubernetes 对象管理</a>，<a href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/imperative-config/">命令式配置</a>和<a href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/declarative-config/">宣告式配置</a>。</p>
<p>运行如下命令查看执行进度信息：</p>
<div class="highlight"><pre><span></span><code># 描述完整信息
kubectl describe deployment mysql
# 仅描述 Pods 信息
kubectl get pods -l app=mysql
</code></pre></div>

<p>（第一个命令）输出示例如下：</p>
<div class="highlight"><pre><span></span><code>...
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   mysql-55cd6b9f47 (1/1 replicas created)
...
</code></pre></div>

<p>对于 <code>get pods</code> 命令，输出示例如下:</p>
<div class="highlight"><pre><span></span><code>NAME                     READY     STATUS    RESTARTS   AGE
mysql-78dbbd9c49-k6sdv   1/1       Running   0          18s
</code></pre></div>

<p>可以使用下面的命令测试数据库实例：</p>
<div class="highlight"><pre><span></span><code>kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -pyourpasswordhere
</code></pre></div>

<p>特别提醒：如果你在这里修改了密码，重新 apply 你的 yaml 文件并不能更新容器。因为数据库是持久化的，密码并不会改变。你需要先使用 <code>kubectl delete -f mysql.yaml</code> 命令删除整个部署。</p>
<p>运行 <code>show databases</code> 后，应该可以看到如下信息：</p>
<div class="highlight"><pre><span></span><code>If you don&#39;t see a command prompt, try pressing enter.

mysql&gt;
mysql&gt;
mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| kube               |
| mysql              |
| performance_schema |
+--------------------+
4 rows in set (0.00 sec)

mysql&gt; exit
Bye
</code></pre></div>

<p>你会注意到，我还将一个<a href="https://github.com/Skarlso/kube-cluster-sample/blob/master/database_setup.sql">数据库初始化 SQL</a> 文件挂载到容器中，MySQL 容器会自动运行该文件，导入我将用到的部分数据和模式。</p>
<p>对应的卷定义如下:</p>
<div class="highlight"><pre><span></span><code><span class="w">  </span><span class="n">volumeMounts</span><span class="p">:</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">mysql</span><span class="o">-</span><span class="n">persistent</span><span class="o">-</span><span class="n">storage</span>
<span class="w">    </span><span class="n">mountPath</span><span class="p">:</span><span class="w"> </span><span class="o">/</span><span class="k">var</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">mysql</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">bootstrap</span><span class="o">-</span><span class="n">script</span>
<span class="w">    </span><span class="n">mountPath</span><span class="p">:</span><span class="w"> </span><span class="o">/</span><span class="n">docker</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="n">initdb</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">database_setup</span><span class="o">.</span><span class="n">sql</span>
<span class="n">volumes</span><span class="p">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">mysql</span><span class="o">-</span><span class="n">persistent</span><span class="o">-</span><span class="n">storage</span>
<span class="w">  </span><span class="n">persistentVolumeClaim</span><span class="p">:</span>
<span class="w">    </span><span class="n">claimName</span><span class="p">:</span><span class="w"> </span><span class="n">mysql</span><span class="o">-</span><span class="n">pv</span><span class="o">-</span><span class="n">claim</span>
<span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="n">bootstrap</span><span class="o">-</span><span class="n">script</span>
<span class="w">  </span><span class="n">hostPath</span><span class="p">:</span>
<span class="w">    </span><span class="n">path</span><span class="p">:</span><span class="w"> </span><span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">hannibal</span><span class="o">/</span><span class="n">golang</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">Skarlso</span><span class="o">/</span><span class="n">kube</span><span class="o">-</span><span class="n">cluster</span><span class="o">-</span><span class="n">sample</span><span class="o">/</span><span class="n">database_setup</span><span class="o">.</span><span class="n">sql</span>
<span class="w">    </span><span class="n">type</span><span class="p">:</span><span class="w"> </span><span class="n">File</span>
</code></pre></div>

<p>（LCTT 译注：数据库初始化脚本需要改成对应的路径，如果是多节点，需要是共享存储中的路径。另外，作者给的 sql 文件似乎有误，<code>person_images</code> 表中的 <code>person_id</code> 列数字都小 1，作者默认 <code>id</code> 从 0 开始，但应该是从 1 开始）</p>
<p>运行如下命令查看引导脚本是否正确执行：</p>
<div class="highlight"><pre><span></span><code><span class="o">~/</span><span class="nt">golang</span><span class="o">/</span><span class="nt">src</span><span class="o">/</span><span class="nt">github</span><span class="p">.</span><span class="nc">com</span><span class="o">/</span><span class="nt">Skarlso</span><span class="o">/</span><span class="nt">kube-cluster-sample</span><span class="o">/</span><span class="nt">kube_files</span><span class="w"> </span><span class="nt">master</span><span class="o">*</span>
<span class="err">❯</span><span class="w"> </span><span class="nt">kubectl</span><span class="w"> </span><span class="nt">run</span><span class="w"> </span><span class="nt">-it</span><span class="w"> </span><span class="nt">--rm</span><span class="w"> </span><span class="nt">--image</span><span class="o">=</span><span class="nt">mysql</span><span class="p">:</span><span class="nd">5</span><span class="p">.</span><span class="nc">6</span><span class="w"> </span><span class="nt">--restart</span><span class="o">=</span><span class="nt">Never</span><span class="w"> </span><span class="nt">mysql-client</span><span class="w"> </span><span class="nt">--</span><span class="w"> </span><span class="nt">mysql</span><span class="w"> </span><span class="nt">-h</span><span class="w"> </span><span class="nt">mysql</span><span class="w"> </span><span class="nt">-uroot</span><span class="w"> </span><span class="nt">-pyourpasswordhere</span><span class="w"> </span><span class="nt">kube</span>
<span class="nt">If</span><span class="w"> </span><span class="nt">you</span><span class="w"> </span><span class="nt">don</span><span class="err">&#39;</span><span class="nt">t</span><span class="w"> </span><span class="nt">see</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">command</span><span class="w"> </span><span class="nt">prompt</span><span class="o">,</span><span class="w"> </span><span class="nt">try</span><span class="w"> </span><span class="nt">pressing</span><span class="w"> </span><span class="nt">enter</span><span class="o">.</span>

<span class="nt">mysql</span><span class="o">&gt;</span><span class="w"> </span><span class="nt">show</span><span class="w"> </span><span class="nt">tables</span><span class="o">;</span>
<span class="o">+</span><span class="nt">----------------</span><span class="o">+</span>
<span class="o">|</span><span class="w"> </span><span class="nt">Tables_in_kube</span><span class="w"> </span><span class="o">|</span>
<span class="o">+</span><span class="nt">----------------</span><span class="o">+</span>
<span class="o">|</span><span class="w"> </span><span class="nt">images</span><span class="w">         </span><span class="o">|</span>
<span class="o">|</span><span class="w"> </span><span class="nt">person</span><span class="w">         </span><span class="o">|</span>
<span class="o">|</span><span class="w"> </span><span class="nt">person_images</span><span class="w">  </span><span class="o">|</span>
<span class="o">+</span><span class="nt">----------------</span><span class="o">+</span>
<span class="nt">3</span><span class="w"> </span><span class="nt">rows</span><span class="w"> </span><span class="nt">in</span><span class="w"> </span><span class="nt">set</span><span class="w"> </span><span class="o">(</span><span class="nt">0</span><span class="p">.</span><span class="nc">00</span><span class="w"> </span><span class="nt">sec</span><span class="o">)</span>

<span class="nt">mysql</span><span class="o">&gt;</span>
</code></pre></div>

<p>（LCTT 译注：上述代码块中的第一行是作者执行命令所在路径，执行第二行的命令无需在该目录中进行）</p>
<p>上述操作完成了数据库服务的初始化。使用如下命令可以查看服务日志：</p>
<div class="highlight"><pre><span></span><code>kubectl logs deployment/mysql -f
</code></pre></div>

<h3>NSQ 查询</h3>
<p>NSQ 查询将以内部服务的形式运行。由于不需要外部访问，这里使用 <code>clusterIP: None</code> 在 Kubernetes 中将其设置为<ruby> 无头服务 <rt>  headless service </rt></ruby>，意味着该服务不使用负载均衡模式，也不使用单独的服务 IP。DNS 将基于服务<ruby> 选择器 <rt>  selectors </rt></ruby>。</p>
<p>我们的 NSQ 查询服务对应的选择器为：</p>
<div class="highlight"><pre><span></span><code>  selector:
    matchLabels:
      app: nsqlookup
</code></pre></div>

<p>那么，内部 DNS 对应的实体类似于：<code>nsqlookup.default.svc.cluster.local</code>。</p>
<p>无头服务的更多细节，可以参考：<a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">无头服务</a>。</p>
<p>NSQ 服务与 MySQL 服务大同小异，只需要少许修改即可。如前所述，我将使用 NSQ 原生的 Docker 镜像，名称为 <code>nsqio/nsq</code>。镜像包含了全部的 nsq 命令，故 nsqd 也将使用该镜像，只是使用的命令不同。对于 nsqlookupd，命令如下：</p>
<div class="highlight"><pre><span></span><code><span class="nx">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;/nsqlookupd&quot;</span><span class="p">]</span>
<span class="nx">args</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;--broadcast-address=nsqlookup.default.svc.cluster.local&quot;</span><span class="p">]</span>
</code></pre></div>

<p>你可能会疑惑，<code>--broadcast-address</code> 参数是做什么用的？默认情况下，<code>nsqlookup</code> 使用容器的主机名作为广播地址；这意味着，当用户运行回调时，回调试图访问的地址类似于 <code>http://nsqlookup-234kf-asdf:4161/lookup?topics=image</code>，但这显然不是我们期望的。将广播地址设置为内部 DNS 后，回调地址将是 <code>http://nsqlookup.default.svc.cluster.local:4161/lookup?topic=images</code>，这正是我们期望的。</p>
<p>NSQ 查询还需要转发两个端口，一个用于广播，另一个用于 nsqd 守护进程的回调。在 Dockerfile 中暴露相应端口，在 Kubernetes 模板中使用它们，类似如下：</p>
<p>容器模板：</p>
<div class="highlight"><pre><span></span><code>        ports:
        - containerPort: 4160
          hostPort: 4160
        - containerPort: 4161
          hostPort: 4161
</code></pre></div>

<p>服务模板：</p>
<div class="highlight"><pre><span></span><code><span class="n">spec</span><span class="o">:</span>
<span class="w">  </span><span class="n">ports</span><span class="o">:</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">main</span>
<span class="w">    </span><span class="n">protocol</span><span class="o">:</span><span class="w"> </span><span class="n">TCP</span>
<span class="w">    </span><span class="n">port</span><span class="o">:</span><span class="w"> </span><span class="mi">4160</span>
<span class="w">    </span><span class="n">targetPort</span><span class="o">:</span><span class="w"> </span><span class="mi">4160</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">secondary</span>
<span class="w">    </span><span class="n">protocol</span><span class="o">:</span><span class="w"> </span><span class="n">TCP</span>
<span class="w">    </span><span class="n">port</span><span class="o">:</span><span class="w"> </span><span class="mi">4161</span>
<span class="w">    </span><span class="n">targetPort</span><span class="o">:</span><span class="w"> </span><span class="mi">4161</span>
</code></pre></div>

<p>端口名称是必须的，Kubernetes 基于名称进行区分。（LCTT 译注：端口名更新为作者 GitHub 对应文件中的名称）</p>
<p>像之前那样，使用如下命令创建服务：</p>
<div class="highlight"><pre><span></span><code>kubectl apply -f nsqlookup.yaml
</code></pre></div>

<p>nsqlookupd 部分到此结束。截至目前，我们已经准备好两个主要的组件。</p>
<h3>接收器</h3>
<p>这部分略微复杂。接收器需要完成三项工作：</p>
<ul>
<li>创建一些部署</li>
<li>创建 nsq 守护进程</li>
<li>将本服务对外公开</li>
</ul>
<h4>部署</h4>
<p>第一个要创建的部署是接收器本身，容器镜像为 <code>skarlso/kube-receiver-alpine</code>。</p>
<h4>NSQ 守护进程</h4>
<p>接收器需要使用 NSQ 守护进程。如前所述，接收器在其内部运行一个 NSQ，这样与 nsq 的通信可以在本地进行，无需通过网络。为了让接收器可以这样操作，NSQ 需要与接收器部署在同一个节点上。</p>
<p>NSQ 守护进程也需要一些调整的参数配置：</p>
<div class="highlight"><pre><span></span><code><span class="w">        </span><span class="nx">ports</span><span class="p">:</span>
<span class="w">        </span><span class="o">-</span><span class="w"> </span><span class="nx">containerPort</span><span class="p">:</span><span class="w"> </span><span class="mi">4150</span>
<span class="w">          </span><span class="nx">hostPort</span><span class="p">:</span><span class="w"> </span><span class="mi">4150</span>
<span class="w">        </span><span class="o">-</span><span class="w"> </span><span class="nx">containerPort</span><span class="p">:</span><span class="w"> </span><span class="mi">4151</span>
<span class="w">          </span><span class="nx">hostPort</span><span class="p">:</span><span class="w"> </span><span class="mi">4151</span>
<span class="w">        </span><span class="nx">env</span><span class="p">:</span>
<span class="w">        </span><span class="o">-</span><span class="w"> </span><span class="nx">name</span><span class="p">:</span><span class="w"> </span><span class="nx">NSQLOOKUP_ADDRESS</span>
<span class="w">          </span><span class="nx">value</span><span class="p">:</span><span class="w"> </span><span class="nx">nsqlookup</span><span class="p">.</span><span class="k">default</span><span class="p">.</span><span class="nx">svc</span><span class="p">.</span><span class="nx">cluster</span><span class="p">.</span><span class="nx">local</span>
<span class="w">        </span><span class="o">-</span><span class="w"> </span><span class="nx">name</span><span class="p">:</span><span class="w"> </span><span class="nx">NSQ_BROADCAST_ADDRESS</span>
<span class="w">          </span><span class="nx">value</span><span class="p">:</span><span class="w"> </span><span class="nx">nsqd</span><span class="p">.</span><span class="k">default</span><span class="p">.</span><span class="nx">svc</span><span class="p">.</span><span class="nx">cluster</span><span class="p">.</span><span class="nx">local</span>
<span class="w">        </span><span class="nx">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;/nsqd&quot;</span><span class="p">]</span>
<span class="w">        </span><span class="nx">args</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;--lookupd-tcp-address=$(NSQLOOKUP_ADDRESS):4160&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;--broadcast-address=$(NSQ_BROADCAST_ADDRESS)&quot;</span><span class="p">]</span>
</code></pre></div>

<p>其中我们配置了 <code>lookup-tcp-address</code> 和 <code>broadcast-address</code> 参数。前者是 nslookup 服务的 DNS 地址，后者用于回调，就像 nsqlookupd 配置中那样。</p>
<h4>对外公开</h4>
<p>下面即将创建第一个对外公开的服务。有两种方式可供选择。考虑到该 API 负载较高，可以使用负载均衡的方式。另外，如果希望将其部署到生产环境中的任选节点，也应该使用负载均衡方式。</p>
<p>但由于我使用的本地集群只有一个节点，那么使用 <code>NodePort</code> 的方式就足够了。<code>NodePort</code> 方式将服务暴露在对应节点的固定端口上。如果未指定端口，将从 30000-32767 数字范围内随机选其一个。也可以指定端口，可以在模板文件中使用 <code>nodePort</code> 设置即可。可以通过 <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code> 访问该服务。如果使用多个节点，负载均衡可以将多个 IP 合并为一个 IP。</p>
<p>更多信息，请参考文档：<a href="https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types">服务发布</a>。</p>
<p>结合上面的信息，我们定义了接收器服务，对应的模板如下：</p>
<div class="highlight"><pre><span></span><code><span class="n">apiVersion</span><span class="o">:</span><span class="w"> </span><span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span><span class="w"> </span><span class="n">Service</span>
<span class="n">metadata</span><span class="o">:</span>
<span class="w">  </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">receiver</span><span class="o">-</span><span class="n">service</span>
<span class="n">spec</span><span class="o">:</span>
<span class="w">  </span><span class="n">ports</span><span class="o">:</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">protocol</span><span class="o">:</span><span class="w"> </span><span class="n">TCP</span>
<span class="w">    </span><span class="n">port</span><span class="o">:</span><span class="w"> </span><span class="mi">8000</span>
<span class="w">    </span><span class="n">targetPort</span><span class="o">:</span><span class="w"> </span><span class="mi">8000</span>
<span class="w">  </span><span class="n">selector</span><span class="o">:</span>
<span class="w">    </span><span class="n">app</span><span class="o">:</span><span class="w"> </span><span class="n">receiver</span>
<span class="w">  </span><span class="n">type</span><span class="o">:</span><span class="w"> </span><span class="n">NodePort</span>
</code></pre></div>

<p>如果希望固定使用 8000 端口，需要增加 <code>nodePort</code> 配置，具体如下：</p>
<div class="highlight"><pre><span></span><code><span class="n">apiVersion</span><span class="o">:</span><span class="w"> </span><span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span><span class="w"> </span><span class="n">Service</span>
<span class="n">metadata</span><span class="o">:</span>
<span class="w">  </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">receiver</span><span class="o">-</span><span class="n">service</span>
<span class="n">spec</span><span class="o">:</span>
<span class="w">  </span><span class="n">ports</span><span class="o">:</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">protocol</span><span class="o">:</span><span class="w"> </span><span class="n">TCP</span>
<span class="w">    </span><span class="n">port</span><span class="o">:</span><span class="w"> </span><span class="mi">8000</span>
<span class="w">    </span><span class="n">targetPort</span><span class="o">:</span><span class="w"> </span><span class="mi">8000</span>
<span class="w">  </span><span class="n">selector</span><span class="o">:</span>
<span class="w">    </span><span class="n">app</span><span class="o">:</span><span class="w"> </span><span class="n">receiver</span>
<span class="w">  </span><span class="n">type</span><span class="o">:</span><span class="w"> </span><span class="n">NodePort</span>
<span class="w">  </span><span class="n">nodePort</span><span class="o">:</span><span class="w"> </span><span class="mi">8000</span>
</code></pre></div>

<p>（LCTT 译注：虽然作者没有写，但我们应该知道需要运行的部署命令 <code>kubectl apply -f receiver.yaml</code>。）</p>
<h3>图片处理器</h3>
<p>图片处理器用于将图片传送至识别组件。它需要访问 nslookupd、 mysql 以及后续部署的人脸识别服务的 gRPC 接口。事实上，这是一个无聊的服务，甚至其实并不是服务（LCTT 译注：第一个服务是指在整个架构中，图片处理器作为一个服务；第二个服务是指 Kubernetes 服务）。它并需要对外暴露端口，这是第一个只包含部署的组件。长话短说，下面是完整的模板：</p>
<p>```</p>
<p>via: <a href="https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/">https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/</a></p>
<p>作者：<a href="https://github.com/Skarlso">hannibal</a> 译者：<a href="https://github.com/pinewall">pinewall</a> 校对：<a href="https://github.com/wxy">wxy</a></p>
<p>本文由 <a href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a href="https://linux.cn/">Linux中国</a> 荣誉推出</p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>