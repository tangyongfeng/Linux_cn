<!DOCTYPE html>
<html lang="zh">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>数据科学家的命令行技巧</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="Author: Kade Killary 对于许多数据科学家来说，数据操作从始至终就是 Pandas 或 Tidyverse。从理论上讲，这样做没有任何问题。毕竟，这就是这些工具 …" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">linux_cn</a></h1>
                <nav><ul>
                    <li><a href="/category/chuan-shan-jia-zhuan-fang">穿山甲专访</a></li>
                    <li><a href="/category/dai-ma-ying-xiong">代码英雄</a></li>
                    <li><a href="/category/fen-xiang">分享</a></li>
                    <li><a href="/category/guan-dian">观点</a></li>
                    <li><a href="/category/huo-dong">活动</a></li>
                    <li><a href="/category/ji-ke-man-hua">极客漫画</a></li>
                    <li class="active"><a href="/category/ji-zhu">技术</a></li>
                    <li><a href="/category/kai-yuan-zhi-hui">开源智慧</a></li>
                    <li><a href="/category/linux-fa-xing-ban">Linux 发行版</a></li>
                    <li><a href="/category/mei-ri-an-quan-zi-xun">每日安全资讯</a></li>
                    <li><a href="/category/misc">Misc</a></li>
                    <li><a href="/category/qu-kuai-lian">区块链</a></li>
                    <li><a href="/category/rong-qi-yu-yun">容器与云</a></li>
                    <li><a href="/category/ruan-jian-kai-fa">软件开发</a></li>
                    <li><a href="/category/shu-mei-pai">树莓派</a></li>
                    <li><a href="/category/xi-tong-yun-wei">系统运维</a></li>
                    <li><a href="/category/xin-wen">新闻</a></li>
                    <li><a href="/category/ying-he-guan-cha">硬核观察</a></li>
                    <li><a href="/category/zhi-ye-sheng-ya">职业生涯</a></li>
                    <li><a href="/category/zhong-jiang-ming-dan">中奖名单</a></li>
                    <li><a href="/category/zhuo-mian-ying-yong">桌面应用</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/2018/12/shu-ju-ke-xue-jia-de-ming-ling-xing-ji-qiao.html" rel="bookmark"
           title="Permalink to 数据科学家的命令行技巧">数据科学家的命令行技巧</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-12-13T22:11:41+01:00">
                Published: Thu 13 December 2018
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/linux-fans-from-china.html">linux fans from china</a>
        </address>
<p>In <a href="/category/ji-zhu">技术</a>.</p>

</footer><!-- /.post-info -->      <p>Author: Kade Killary</p>
<p><img alt="" src="/data/attachment/album/201812/13/221149dirhh8vthq2vll9j.png"></p>
<p>对于许多数据科学家来说，数据操作从始至终就是 Pandas 或 Tidyverse。从理论上讲，这样做没有任何问题。毕竟，这就是这些工具存在的原因。然而，对于像分隔符转换这样的简单任务，这些工具是大材小用了。</p>
<p>立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。学习 shell 的来龙去脉将无可否认地提高你的生产力。除此之外，命令行还是计算领域的一个重要历史课程。例如，awk —— 一种数据驱动的脚本语言。1977 年，在 <a href="https://en.wikipedia.org/wiki/Brian_Kernighan">Brain Kernighan</a>（即传奇的 <a href="https://en.wikipedia.org/wiki/The_C_Programming_Language">K&amp;R 书</a>中 K）的帮助下，awk 首次出现。今天，大约五十年过去了，awk 仍然活跃在每年<a href="https://www.amazon.com/Learning-AWK-Programming-cutting-edge-text-processing-ebook/dp/B07BT98HDS">新出版的书</a>里面。因此，可以安全地假设对命令行魔法的付出不会很快贬值。</p>
<h3>我们将涵盖什么</h3>
<ul>
<li>ICONV</li>
<li>HEAD</li>
<li>TR</li>
<li>WC</li>
<li>SPLIT</li>
<li>SORT &amp; UNIQ</li>
<li>CUT</li>
<li>PASTE</li>
<li>JOIN</li>
<li>GREP</li>
<li>SED</li>
<li>AWK</li>
</ul>
<h3>ICONV</h3>
<p>文件编码可能会很棘手。现在大部分文件都是 UTF-8 编码的。要了解 UTF-8 背后的一些魔力，请查看这个出色的<a href="https://www.youtube.com/watch?v=MijmeoH9LT4">视频</a>。尽管如此，有时我们收到的文件不是这种编码。这可能引起对改变编码模式的一些胡乱尝试。这里，<code>iconv</code> 是一个拯救者。<code>iconv</code> 是一个简单的程序，它将获取采用一种编码的文本并输出采用另一种编码的文本。</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> Converting -f (from) latin1 (ISO-8859-1)
<span class="gh">#</span> -t (to) standard UTF_8

iconv -f ISO-8859-1 -t UTF-8 &lt; input.txt &gt; output.txt
</code></pre></div>

<p>实用选项：</p>
<ul>
<li><code>iconv -l</code> 列出所有已知编码</li>
<li><code>iconv -c</code> 默默丢弃无法转换的字符</li>
</ul>
<h3>HEAD</h3>
<p>如果你是一个 Pandas 重度用户，那么会很熟悉 <code>head</code>。通常在处理新数据时，我们想做的第一件事就是了解其内容。这就得启动 Pandas，读取数据然后调用 <code>df.head()</code> —— 要说这有点费劲。没有任何选项的 <code>head</code> 将打印出文件的前 10 行。<code>head</code> 的真正力量在于干净利落的测试操作。例如，如果我们想将文件的分隔符从逗号更改为管道。一个快速测试将是：<code>head mydata.csv | sed 's/,/|/g'</code>。</p>
<div class="highlight"><pre><span></span><code># Prints out first 10 lines
head filename.csv

# Print first 3 lines
head -n 3 filename.csv
</code></pre></div>

<p>实用选项：</p>
<ul>
<li><code>head -n</code> 打印特定行数</li>
<li><code>head -c</code> 打印特定字节数</li>
</ul>
<h3>TR</h3>
<p><code>tr</code> 类似于翻译。这个功能强大的实用程序是文件基础清理的主力。理想的用例是替换文件中的分隔符。</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> Converting a tab delimited file into commas
cat tab_delimited.txt | tr &quot;\t&quot; &quot;,&quot; comma_delimited.csv
</code></pre></div>

<p><code>tr</code> 另一个功能是你可以用内建 <code>[:class:]</code> 变量（POSIX 字符类）发挥威力。这些包括了：</p>
<ul>
<li><code>[:alnum:]</code> 所有字母和数字</li>
<li><code>[:alpha:]</code> 所有字母</li>
<li><code>[:blank:]</code> 所有水平空白</li>
<li><code>[:cntrl:]</code> 所有控制字符</li>
<li><code>[:digit:]</code> 所有数字</li>
<li><code>[:graph:]</code> 所有可打印字符，但不包括空格</li>
<li><code>[:lower:]</code> 所有小写字母</li>
<li><code>[:print:]</code> 所有可打印字符，包括空格</li>
<li><code>[:punct:]</code> 所有标点符号</li>
<li><code>[:space:]</code> 所有水平或垂直空白</li>
<li><code>[:upper:]</code> 所有大写字母</li>
<li><code>[:xdigit:]</code> 所有 16 进制数字</li>
</ul>
<p>你可以将这些连接在一起以组成强大的程序。以下是一个基本的字数统计程序，可用于检查 README 是否被滥用。</p>
<div class="highlight"><pre><span></span><code>cat README.md | tr &quot;[:punct:][:space:]&quot; &quot;\n&quot; | tr &quot;[:upper:]&quot; &quot;[:lower:]&quot; | grep . | sort | uniq -c | sort -nr
</code></pre></div>

<p>另一个使用基本正则表达式的例子：</p>
<div class="highlight"><pre><span></span><code># Converting all upper case letters to lower case
cat filename.csv | tr &#39;[A-Z]&#39; &#39;[a-z]&#39;
</code></pre></div>

<p>实用选项：</p>
<ul>
<li><code>tr -d</code> 删除字符</li>
<li><code>tr -s</code> 压缩字符</li>
<li><code>\b</code> 退格</li>
<li><code>\f</code> 换页</li>
<li><code>\v</code> 垂直制表符</li>
<li><code>\NNN</code> 八进制字符</li>
</ul>
<h3>WC</h3>
<p>单词计数。它的价值主要来自其 <code>-l</code> 选项，它会给你提供行数。</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> Will return number of lines in CSV
wc -l gigantic_comma.csv
</code></pre></div>

<p>这个工具可以方便地确认各种命令的输出。所以，如果我们在转换文件中的分隔符之后运行 <code>wc -l</code>，我们会期待总行数是一样的，如果不一致，我们就知道有地方出错了。</p>
<p>实用选项：</p>
<ul>
<li><code>wc -c</code> 打印字节数</li>
<li><code>wc -m</code> 打印字符数</li>
<li><code>wc -L</code> 打印最长行的长度</li>
<li><code>wc -w</code> 打印单词数量</li>
</ul>
<h3>SPLIT</h3>
<p>文件大小的范围可以很广。对于有的任务，拆分文件或许是有好处的，所以使用 <code>split</code> 吧。<code>split</code> 的基本语法是：</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> We will split our CSV into new_filename every 500 lines
split -l 500 filename.csv new_filename_
<span class="gh">#</span> filename.csv
<span class="gh">#</span> ls output
<span class="gh">#</span> new_filename_aaa
<span class="gh">#</span> new_filename_aab
<span class="gh">#</span> new_filename_aa
</code></pre></div>

<p>它有两个奇怪的地方是命名约定和缺少文件扩展名。后缀约定可以通过 <code>-d</code> 标志变为数字。要添加文件扩展名，你需要运行以下 <code>find</code> 命令。它将通过附加 <code>.csv</code> 扩展名来更改当前目录中所有文件的名称，所以小心了。</p>
<div class="highlight"><pre><span></span><code><span class="nx">find</span><span class="w"> </span><span class="p">.</span><span class="w"> </span><span class="o">-</span><span class="k">type</span><span class="w"> </span><span class="nx">f</span><span class="w"> </span><span class="o">-</span><span class="nx">exec</span><span class="w"> </span><span class="nx">mv</span><span class="w"> </span><span class="err">&#39;</span><span class="p">{}</span><span class="sc">&#39; &#39;</span><span class="p">{}</span><span class="err">&#39;</span><span class="p">.</span><span class="nx">csv</span><span class="w"> </span><span class="err">\</span><span class="p">;</span>
<span class="err">#</span><span class="w"> </span><span class="nx">ls</span><span class="w"> </span><span class="nx">output</span>
<span class="err">#</span><span class="w"> </span><span class="nx">filename</span><span class="p">.</span><span class="nx">csv</span><span class="p">.</span><span class="nx">csv</span>
<span class="err">#</span><span class="w"> </span><span class="nx">new_filename_aaa</span><span class="p">.</span><span class="nx">csv</span>
<span class="err">#</span><span class="w"> </span><span class="nx">new_filename_aab</span><span class="p">.</span><span class="nx">csv</span>
<span class="err">#</span><span class="w"> </span><span class="nx">new_filename_aac</span><span class="p">.</span><span class="nx">csv</span>
</code></pre></div>

<p>实用选项：</p>
<ul>
<li><code>split -b N</code> 按特定字节大小分割</li>
<li><code>split -a N</code> 生成长度为 N 的后缀</li>
<li><code>split -x</code> 使用十六进制后缀</li>
</ul>
<h3>SORT &amp; UNIQ</h3>
<p>上面两个命令很明显：它们的作用就是字面意思。这两者结合起来可以提供最强大的冲击 (例如，唯一单词的数量)。这是由于 <code>uniq</code> 只作用于重复的相邻行。这也是在输出前进行 <code>sort</code> 的原因。一个有趣的事情是 <code>sort -u</code> 会达到和典型的 <code>sort file.txt | uniq</code> 模式一样的结果。</p>
<p><code>sort</code> 对数据科学家来说确实具有潜在的有用能力：能够根据特定列对整个 CSV 进行排序。</p>
<div class="highlight"><pre><span></span><code># Sorting a CSV file by the second column alphabetically
sort -t&quot;,&quot; -k2,2 filename.csv

# Numerically
sort -t&quot;,&quot; -k2n,2 filename.csv

# Reverse order
sort -t&quot;,&quot; -k2nr,2 filename.csv
</code></pre></div>

<p>这里的 <code>-t</code> 选项将逗号指定为分隔符，通常假设分隔符是空格或制表符。此外，<code>-k</code> 选项是为了确定我们的键。这里的语法是 <code>-km,n</code>，<code>m</code> 作为开始列，<code>n</code> 作为结束列。</p>
<p>实用选项：</p>
<ul>
<li><code>sort -f</code> 忽略大小写</li>
<li><code>sort -r</code> 反向排序</li>
<li><code>sort -R</code> 乱序</li>
<li><code>uniq -c</code> 统计出现次数</li>
<li><code>uniq -d</code> 只打印重复行</li>
</ul>
<h3>CUT</h3>
<p><code>cut</code> 用于删除列。作为演示，如果我们只想删除第一和第三列。</p>
<div class="highlight"><pre><span></span><code>cut -d, -f 1,3 filename.csv
</code></pre></div>

<p>要选择除了第一行外的所有行。</p>
<div class="highlight"><pre><span></span><code>cut -d, -f 2- filename.csv
</code></pre></div>

<p>结合其他命令，将 <code>cut</code> 用作过滤器。</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> Print first 10 lines of column 1 and 3, where &quot;some_string_value&quot; is present
head filename.csv | grep &quot;some_string_value&quot; | cut -d, -f 1,3
</code></pre></div>

<p>查出第二列中唯一值的数量。</p>
<div class="highlight"><pre><span></span><code>cat filename.csv | cut -d, -f 2 | sort | uniq | wc -l

# Count occurences of unique values, limiting to first 10 results
cat filename.csv | cut -d, -f 2 | sort | uniq -c | head
</code></pre></div>

<h3>PASTE</h3>
<p><code>paste</code> 是一个带有趣味性功能的特定命令。如果你有两个需要合并的文件，并且它们已经排序好了，<code>paste</code> 帮你解决了接下来的步骤。</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> names.txt
adam
john
zach

<span class="gh">#</span> jobs.txt
lawyer
youtuber
developer

<span class="gh">#</span> Join the two into a CSV
paste -d &#39;,&#39; names.txt jobs.txt &gt; person_data.txt

<span class="gh">#</span> Output
adam,lawyer
john,youtuber
zach,developer
</code></pre></div>

<p>更多 SQL 式变种，见下文。</p>
<h3>JOIN</h3>
<p><code>join</code> 是一个简单的、<ruby> 准切向的 <rt>  quasi-tangential </rt></ruby> SQL。最大的区别是 <code>join</code> 将返回所有列以及只能在一个字段上匹配。默认情况下，<code>join</code> 将尝试使用第一列作为匹配键。为了获得不同结果，必须使用以下语法：</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> Join the first file (-1) by the second column
<span class="gh">#</span> and the second file (-2) by the first
join -t &quot;,&quot; -1 2 -2 1 first_file.txt second_file.txt
</code></pre></div>

<p>标准的 <code>join</code> 是内连接。然而，外连接通过 <code>-a</code> 选项也是可行的。另一个值得一提的技巧是 <code>-q</code> 标志，如果发现有缺失的字段，可用于替换值。</p>
<div class="highlight"><pre><span></span><code><span class="gh">#</span> Outer join, replace blanks with NULL in columns 1 and 2
<span class="gh">#</span> -o which fields to substitute - 0 is key, 1.1 is first column, etc...
join -t&quot;,&quot; -1 2 -a 1 -a2 -e &#39; NULL&#39; -o &#39;0,1.1,2.2&#39; first_file.txt second_file.txt
</code></pre></div>

<p>它不是最用户友好的命令，而是绝望时刻的绝望措施。</p>
<p>实用选项：</p>
<ul>
<li><code>join -a</code> 打印不可配对的行</li>
<li><code>join -e</code> 替换丢失的输入字段</li>
<li><code>join -j</code> 相当于 <code>-1 FIELD -2 FIELD</code></li>
</ul>
<h3>GREP</h3>
<p><code>grep</code> 即 <ruby> 用正则表达式全局搜索并且打印 <rt>  Global search for a Regular Expression and Print </rt></ruby>，可能是最有名的命令，并且名副其实。<code>grep</code> 很强大，特别适合在大型代码库中查找。在数据科学的王国里，它充当其他命令的提炼机制。虽然它的标准用途也很有价值。</p>
<div class="highlight"><pre><span></span><code># Recursively search and list all files in directory containing &#39;word&#39;

grep -lr &#39;word&#39; .

# List number of files containing word

grep -lr &#39;word&#39; . | wc -l
</code></pre></div>

<p>计算包含单词或模式的总行数。</p>
<div class="highlight"><pre><span></span><code>grep -c &#39;some_value&#39; filename.csv

<span class="gh">#</span> Same thing, but in all files in current directory by file name

grep -c &#39;some_value&#39; *
</code></pre></div>

<p>对多个值使用“或”运算符： <code>\|</code>。</p>
<div class="highlight"><pre><span></span><code>grep &quot;first_value\|second_value&quot; filename.csv
</code></pre></div>

<p>实用选项：</p>
<ul>
<li><code>alias grep="grep --color=auto"</code> 使 grep 色彩丰富</li>
<li><code>grep -E</code> 使用扩展正则表达式</li>
<li><code>grep -w</code> 只匹配整个单词</li>
<li><code>grep -l</code> 打印匹配的文件名</li>
<li><code>grep -v</code> 非匹配</li>
</ul>
<h3>大人物们</h3>
<p><code>sed</code> 和 <code>awk</code> 是本文中最强大的两个命令。为简洁起见，我不打算详细讨论这两个命令。相反，我将介绍各种能证明其令人印象深刻的力量的命令。如果你想了解更多，<a href="https://www.amazon.com/sed-awk-Dale-Dougherty/dp/1565922255/ref=sr_1_1?ie=UTF8&amp;qid=1524381457&amp;sr=8-1&amp;keywords=sed+and+awk">这儿就有一本书</a>是关于它们的。</p>
<h3>SED</h3>
<p><code>sed</code> 本质上是一个流编辑器。它擅长替换，但也可以用于所有输出重构。</p>
<p>最基本的 <code>sed</code> 命令由 <code>s/old/new/g</code> 组成。它的意思是搜索 <code>old</code>，全局替换为 <code>new</code>。 如果没有 <code>/g</code>，我们的命令将在 <code>old</code> 第一次出现后终止。</p>
<p>为了快速了解它的功能，我们可以深入了解一个例子。 在以下情景中，你已有以下文件：</p>
<div class="highlight"><pre><span></span><code>balance,name
$1,000,john
$2,000,jack
</code></pre></div>

<p>我们可能想要做的第一件事是删除美元符号。<code>-i</code> 标志表示原位。<code>''</code> 表示零长度文件扩展名，从而覆盖我们的初始文件。理想情况下，你可以单独测试，然后输出到新文件。</p>
<div class="highlight"><pre><span></span><code>sed -i &#39;&#39; &#39;s/\$//g&#39; data.txt
# balance,name
# 1,000,john
# 2,000,jack
</code></pre></div>

<p>接下来，去除 <code>blance</code> 列的逗号。</p>
<div class="highlight"><pre><span></span><code>sed -i &#39;&#39; &#39;s/\([0-9]\),\([0-9]\)/\1\2/g&#39; data.txt
# balance,name
# 1000,john
# 2000,jack
</code></pre></div>

<p>最后 jack 有一天决定辞职。所以，再见了，我的朋友。</p>
<div class="highlight"><pre><span></span><code>sed -i &#39;&#39; &#39;/jack/d&#39; data.txt
# balance,name
# 1000,john
</code></pre></div>

<p>正如你所看到的，<code>sed</code> 有很多强大的功能，但乐趣并不止于此。</p>
<h3>AWK</h3>
<p>最好的留在最后。<code>awk</code> 不仅仅是一个简单的命令：它是一个成熟的语言。在本文中涉及的所有内容中，<code>awk</code> 是目前为止最酷的。如果你感兴趣，这里有很多很棒的资源 —— 看 <a href="https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X/ref=sr_1_1?ie=UTF8&amp;qid=1524388936&amp;sr=8-1&amp;keywords=awk">这里</a>、<a href="http://www.grymoire.com/Unix/Awk.html">这里</a> 和 <a href="https://www.tutorialspoint.com/awk/index.htm">这里</a>。</p>
<p><code>awk</code> 的常见用例包括：</p>
<ul>
<li>文字处理</li>
<li>格式化文本报告</li>
<li>执行算术运算</li>
<li>执行字符串操作</li>
</ul>
<p><code>awk</code> 可以以最原生的形式并行 <code>grep</code>。</p>
<div class="highlight"><pre><span></span><code>awk &#39;/word/&#39; filename.csv
</code></pre></div>

<p>或者更加神奇：将 <code>grep</code> 和 <code>cut</code> 组合起来。在这里，对于所有带我们指定单词 <code>word</code> 的行，<code>awk</code> 打印第三和第四列，用 <code>tab</code> 分隔。<code>-F,</code> 用于指定切分时的列分隔符为逗号。</p>
<div class="highlight"><pre><span></span><code>awk -F, &#39;/word/ { print $3 &quot;\t&quot; $4 }&#39; filename.csv
</code></pre></div>

<p><code>awk</code> 内置了许多精巧的变量。比如，<code>NF</code> —— 字段数，和 <code>NR</code> —— 记录数。要获取文件中的第 53 条记录：</p>
<div class="highlight"><pre><span></span><code>awk -F, &#39;NR == 53&#39; filename.csv
</code></pre></div>

<p>更多的花招是其基于一个或多个值进行过滤的能力。下面的第一个示例将打印第一列等于给定字符串的行的行号和列。</p>
<div class="highlight"><pre><span></span><code>awk -F, &#39; $1 == &quot;string&quot; { print NR, $0 } &#39; filename.csv

# Filter based off of numerical value in second column
awk -F, &#39; $2 == 1000 { print NR, $0 } &#39; filename.csv
</code></pre></div>

<p>多个数值表达式：</p>
<div class="highlight"><pre><span></span><code># Print line number and columns where column three greater
# than 2005 and column five less than one thousand

awk -F, &#39; $3 &gt;= 2005 &amp;&amp; $5 &lt;= 1000 { print NR, $0 } &#39; filename.csv
</code></pre></div>

<p>求出第三列的总和：</p>
<div class="highlight"><pre><span></span><code><span class="n">awk</span> <span class="o">-</span><span class="n">F</span><span class="p">,</span> <span class="s">&#39;{ x+=$3 } END { print x }&#39;</span> <span class="n">filename</span><span class="p">.</span><span class="n">csv</span>
</code></pre></div>

<p>在第一列等于 <code>something</code> 的那些行，求出第三列值的总和。</p>
<div class="highlight"><pre><span></span><code><span class="n">awk</span> <span class="o">-</span><span class="n">F</span><span class="p">,</span> <span class="s">&#39;$1 == &quot;something&quot; { x+=$3 } END { print x }&#39;</span> <span class="n">filename</span><span class="p">.</span><span class="n">csv</span>
</code></pre></div>

<p>获取文件的行列数：</p>
<div class="highlight"><pre><span></span><code><span class="n">awk</span> <span class="o">-</span><span class="n">F</span><span class="p">,</span> <span class="s">&#39;END { print NF, NR }&#39;</span> <span class="n">filename</span><span class="p">.</span><span class="n">csv</span>

<span class="o">#</span> <span class="n">Prettier</span> <span class="n">version</span>
<span class="n">awk</span> <span class="o">-</span><span class="n">F</span><span class="p">,</span> <span class="s">&#39;BEGIN { print &quot;COLUMNS&quot;, &quot;ROWS&quot; }; END { print NF, NR }&#39;</span> <span class="n">filename</span><span class="p">.</span><span class="n">csv</span>
</code></pre></div>

<p>打印出现了两次的行：</p>
<div class="highlight"><pre><span></span><code>awk -F, &#39;++seen[$0] == 2&#39; filename.csv
</code></pre></div>

<p>删除重复的行：</p>
<div class="highlight"><pre><span></span><code># Consecutive lines
awk &#39;a !~ $0; {a=$0}&#39;]

# Nonconsecutive lines
awk &#39;! a[$0]++&#39; filename.csv

# More efficient
awk &#39;!($0 in a) {a[$0];print}
</code></pre></div>

<p>使用内置函数 <code>gsub()</code> 替换多个值。</p>
<div class="highlight"><pre><span></span><code>awk &#39;{gsub(/scarlet|ruby|puce/, &quot;red&quot;); print}&#39;
</code></pre></div>

<p>这个 <code>awk</code> 命令将组合多个 CSV 文件，忽略标题，然后在最后附加它。</p>
<div class="highlight"><pre><span></span><code>awk &#39;FNR==1 &amp;&amp; NR!=1{next;}{print}&#39; *.csv &gt; final_file.csv
</code></pre></div>

<p>需要缩小一个庞大的文件？ <code>awk</code> 可以在 <code>sed</code> 的帮助下处理它。具体来说，该命令根据行数将一个大文件分成多个较小的文件。这个一行脚本将增加一个扩展名。</p>
<div class="highlight"><pre><span></span><code><span class="nt">sed</span><span class="w"> </span><span class="s1">&#39;1d;$d&#39;</span><span class="w"> </span><span class="nt">filename</span><span class="p">.</span><span class="nc">csv</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nt">awk</span><span class="w"> </span><span class="s1">&#39;NR%NUMBER_OF_LINES==1{x=&quot;filename-&quot;++i&quot;.csv&quot;;}{print &gt; x}&#39;</span>

<span class="err">#</span><span class="w"> </span><span class="nt">Example</span><span class="o">:</span><span class="w"> </span><span class="nt">splitting</span><span class="w"> </span><span class="nt">big_data</span><span class="p">.</span><span class="nc">csv</span><span class="w"> </span><span class="nt">into</span><span class="w"> </span><span class="nt">data_</span><span class="o">(</span><span class="nt">n</span><span class="o">)</span><span class="p">.</span><span class="nc">csv</span><span class="w"> </span><span class="nt">every</span><span class="w"> </span><span class="nt">100</span><span class="o">,</span><span class="nt">000</span><span class="w"> </span><span class="nt">lines</span>
<span class="nt">sed</span><span class="w"> </span><span class="s1">&#39;1d;$d&#39;</span><span class="w"> </span><span class="nt">big_data</span><span class="p">.</span><span class="nc">csv</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nt">awk</span><span class="w"> </span><span class="s1">&#39;NR%100000==1{x=&quot;data_&quot;++i&quot;.csv&quot;;}{print &gt; x}&#39;</span>
</code></pre></div>

<h3>结语</h3>
<p>命令行拥有无穷无尽的力量。本文中介绍的命令足以将你从一无所知提升到英雄人物。除了涵盖的内容之外，还有许多实用程序可以考虑用于日常数据操作。<a href="http://csvkit.readthedocs.io/en/1.0.3/">Csvkit</a>、<a href="https://github.com/BurntSushi/xsv">xsv</a> 还有 <a href="https://github.com/harelba/q">q</a> 是需要记住的三个。如果你希望更深入地了解命令行数据科学，查看<a href="https://www.amazon.com/Data-Science-Command-Line-Time-Tested/dp/1491947853/ref=sr_1_1?ie=UTF8&amp;qid=1524390894&amp;sr=8-1&amp;keywords=data+science+at+the+command+line">这本书</a>。它也可以<a href="https://www.datascienceatthecommandline.com/">免费</a>在线获得！</p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>