<!DOCTYPE html>
<html lang="zh">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>如何使用机器学习来分析情感</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="Author: Jishnu Saurav Mittapalli 本文将帮助你理解 情感分析 sentiment analysis 的概念，并且学习如何使用机器学习进行情感分析。我们使用了不同的机器学 …" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">linux_cn</a></h1>
                <nav><ul>
                    <li><a href="/category/chuan-shan-jia-zhuan-fang">穿山甲专访</a></li>
                    <li><a href="/category/dai-ma-ying-xiong">代码英雄</a></li>
                    <li><a href="/category/fen-xiang">分享</a></li>
                    <li><a href="/category/guan-dian">观点</a></li>
                    <li><a href="/category/huo-dong">活动</a></li>
                    <li><a href="/category/ji-ke-man-hua">极客漫画</a></li>
                    <li><a href="/category/ji-zhu">技术</a></li>
                    <li><a href="/category/kai-yuan-zhi-hui">开源智慧</a></li>
                    <li><a href="/category/linux-fa-xing-ban">Linux 发行版</a></li>
                    <li><a href="/category/mei-ri-an-quan-zi-xun">每日安全资讯</a></li>
                    <li><a href="/category/misc">Misc</a></li>
                    <li><a href="/category/qu-kuai-lian">区块链</a></li>
                    <li><a href="/category/rong-qi-yu-yun">容器与云</a></li>
                    <li class="active"><a href="/category/ruan-jian-kai-fa">软件开发</a></li>
                    <li><a href="/category/shu-mei-pai">树莓派</a></li>
                    <li><a href="/category/xi-tong-yun-wei">系统运维</a></li>
                    <li><a href="/category/xin-wen">新闻</a></li>
                    <li><a href="/category/ying-he-guan-cha">硬核观察</a></li>
                    <li><a href="/category/zhi-ye-sheng-ya">职业生涯</a></li>
                    <li><a href="/category/zhong-jiang-ming-dan">中奖名单</a></li>
                    <li><a href="/category/zhuo-mian-ying-yong">桌面应用</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/2023/02/ru-he-shi-yong-ji-qi-xue-xi-lai-fen-xi-qing-gan.html" rel="bookmark"
           title="Permalink to 如何使用机器学习来分析情感">如何使用机器学习来分析情感</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-02-03T11:22:59+01:00">
                Published: Fri 03 February 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/linux-fans-from-china.html">linux fans from china</a>
        </address>
<p>In <a href="/category/ruan-jian-kai-fa">软件开发</a>.</p>

</footer><!-- /.post-info -->      <p>Author: Jishnu Saurav Mittapalli</p>
<p><img alt="" src="/data/attachment/album/202302/03/112201q909lsqqs9e0jjzc.jpg"></p>
<p>本文将帮助你理解 <ruby> 情感分析 <rt>  sentiment analysis </rt></ruby> 的概念，并且学习如何使用机器学习进行情感分析。我们使用了不同的机器学习算法进行情感分析，然后将各个算法的准确率结果进行比较，以确定哪一种算法最适合这个问题。</p>
<p>情感分析是自然语言处理（NLP）中的一个重要的内容。情感指的是我们对某一事件、物品、情况或事物产生的感觉。情感分析是一个从文本中自动提取人类情感的研究领域。它在上世纪 90 年代初才慢慢地开始发展起来。</p>
<p>本文将让你明白如何将机器学习（ML）用于情感分析，并比较不同机器学习算法的结果。本文的目标不在于研究如何提高算法性能。</p>
<p>如今，我们生活在一个快节奏的社会中，所有的商品都能在网上购买到，每个人都可以在网上发表自己的评论。而一些商品的负面网络评论可能会损害公司的声誉，从而影响公司的销售额。因此对公司来说，通过商品评论来了解客户真正想要什么变得非常重要。但是这些评论数据太多了，无法一个个地手动查看所有的评论。这就是情绪分析诞生的缘由。</p>
<p>现在，就让我们看看如何用机器学习开发一个模型，来进行基本的情绪分析吧。</p>
<h3>现在就开始吧！</h3>
<h4>获取数据</h4>
<p>第一步是选择一个数据集。你可以从任何公开的评论中进行选择，例如推文或电影评论。数据集中至少要包含两列：标签和实际的文本段。</p>
<p>下图显示了我们选取的部分数据集。</p>
<p><img alt="Figure 1: Data sample" src="/data/attachment/album/202302/03/112300bjhjhs0u5pjop58n.jpg"></p>
<p>接下来，我们导入所需的库：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
</code></pre></div>

<p>正如你在上面代码看到，我们导入了 <code>NumPy</code> 和 <code>Pandas</code> 库来处理数据。至于其他库，我们会在使用到它们时再说明。</p>
<p>数据集已准备就绪，并且已导入所需的库。接着，我们需要用 <code>Pandas</code> 库将数据集读入到我们的项目中去。我们使用以下的代码将数据集读入 Pandas <ruby> 数据帧 <rt>  DataFrame </rt></ruby> 类型：</p>
<div class="highlight"><pre><span></span><code>sentiment_dataframe = pd.read_csv(“/content/drive/MyDrive/Data/sentiments - sentiments.tsv”,sep = ‘\t’)
</code></pre></div>

<h4>数据处理</h4>
<p>现在我们的项目中已经导入好数据集了。然后，我们要对数据进行处理，以便算法可以更好地理解数据集的特征。我们首先为数据集中的列命名，通过下面的代码来完成：</p>
<div class="highlight"><pre><span></span><code>sentiment_dataframe.columns = [“label”,”body_text”]
</code></pre></div>

<p>然后，我们对 <code>label</code> 列进行数值化：<code>negative</code> 的评论替换为 1，<code>positive</code> 的评论替换为 0。下图显示了经过基本修改后的 <code>sentiment_dataframe</code> 的值。</p>
<p><img alt="Figure 2: Data frame with basic modifications" src="/data/attachment/album/202302/03/112300n5ickmgi5585hm13.jpg"></p>
<h4>准备好特征值、目标值</h4>
<p>下一步是数据的预处理。这是非常重要的一步，因为机器学习算法只能理解/处理数值形数据，而不能理解文本，所以此时要进行特征抽取，将字符串/文本转换成数值化的数据。此外，还需要删除冗余和无用的数据，因为这些数据可能会污染我们的训练模型。我们在这一步中去除了噪声数据、缺失值数据和不一致的数据。</p>
<p>对于情感分析，我们在数据帧中添加特征文本的长度和标点符号计数。我们还要进行词干提取，即将所有相似词（如 “give”、“giving” 等）转换为单一形式。完成后，我们将数据集分为两部分：特征值 X 和 目标值 Y。</p>
<p>上述内容是使用以下代码完成的。下图显示了执行这些步骤后的数据帧。</p>
<p><img alt="Figure 3: Data frame after the division of the data set" src="/data/attachment/album/202302/03/112300yeekkkybk44jc50w.jpg"></p>
<div class="highlight"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">count_punct</span><span class="p">(</span><span class="nc">text</span><span class="p">)</span><span class="err">:</span>
<span class="w">   </span><span class="nf">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="o">[</span><span class="n">1 for char in text if char in string.punctuation</span><span class="o">]</span><span class="p">)</span>
<span class="w">   </span><span class="k">return</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="nf">count</span><span class="o">/</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="nc">text</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">text</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="err">“</span><span class="w"> </span><span class="err">“</span><span class="p">)),</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>

<span class="n">tokenized_tweet</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘body_text’</span><span class="o">]</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="nl">x</span><span class="p">:</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">stemmer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">PorterStemmer</span><span class="p">()</span>
<span class="n">tokenized_tweet</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tokenized_tweet</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="nl">x</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">stemmer.stem(i) for i in x</span><span class="o">]</span><span class="p">)</span>
<span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">tokenized_tweet</span><span class="p">))</span><span class="err">:</span>
<span class="w">   </span><span class="n">tokenized_tweet</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">‘</span><span class="w"> </span><span class="err">‘</span><span class="p">.</span><span class="k">join</span><span class="p">(</span><span class="n">tokenized_tweet</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">)</span>
<span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘body_text’</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tokenized_tweet</span>
<span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘body_len’</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘body_text’</span><span class="o">]</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="nl">x</span><span class="p">:</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="err">“</span><span class="w"> </span><span class="err">“</span><span class="p">))</span>
<span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘punct%’</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘body_text’</span><span class="o">]</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="nl">x</span><span class="p">:</span><span class="n">count_punct</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘body_text’</span><span class="o">]</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sentiment_dataframe</span><span class="o">[</span><span class="n">‘label’</span><span class="o">]</span>
</code></pre></div>

<h4>特征工程：文本特征处理</h4>
<p>我们接下来进行文本特征抽取，对文本特征进行数值化。为此，我们使用<ruby> 计数向量器 <rt>  CountVectorizer </rt></ruby>，它返回词频矩阵。</p>
<p>在此之后，计算数据帧 X 中的文本长度和标点符号计数等特征。X 的示例如下图所示。</p>
<p><img alt="Figure 4: Sample of final features" src="/data/attachment/album/202302/03/112300j0cgoo0sqgxp3isx.jpg"></p>
<h4>使用的机器学习算法</h4>
<p>现在数据已经可以训练了。下一步是确定使用哪些算法来训练模型。如前所述，我们将尝试多种机器学习算法，并确定最适合情感分析的算法。由于我们打算对文本进行二元分类，因此我们使用以下算法：</p>
<ul>
<li>K-近邻算法（KNN）</li>
<li>逻辑回归算法</li>
<li>支持向量机（SVMs）</li>
<li>随机梯度下降（SGD）</li>
<li>朴素贝叶斯算法</li>
<li>决策树算法</li>
<li>随机森林算法</li>
</ul>
<h4>划分数据集</h4>
<p>首先，将数据集划分为训练集和测试集。使用 <code>sklearn</code> 库，详见以下代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">99</span><span class="p">)</span>
</code></pre></div>

<p>我们使用 20% 的数据进行测试，80% 的数据用于训练。划分数据的意义在于对一组新数据（即测试集）评估我们训练的模型是否有效。</p>
<h5>K-近邻算法</h5>
<p>现在，让我们开始训练第一个模型。首先，我们使用 KNN 算法。先训练模型，然后再评估模型的准确率（具体的代码都可以使用 Python 的 <code>sklearn</code> 库来完成）。详见以下代码，KNN 训练模型的准确率大约为 50%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.5056689342403629</span>
</code></pre></div>

<h5>逻辑回归算法</h5>
<p>逻辑回归模型的代码十分类似——首先从库中导入函数，拟合模型，然后对模型进行评估。下面的代码使用逻辑回归算法，准确率大约为 66%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.6621315192743764</span>
</code></pre></div>

<h5>支持向量机算法</h5>
<p>以下代码使用 SVM，准确率大约为 67%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="err">’</span><span class="n">linear</span><span class="err">’</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.6780045351473923</span>
</code></pre></div>

<h5>随机森林算法</h5>
<p>以下的代码使用了随机森林算法，随机森林训练模型的准确率大约为 69%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.6938775510204082</span>
</code></pre></div>

<h5>决策树算法</h5>
<p>接下来，我们使用决策树算法，其准确率约为 61%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.6190476190476191</span>
</code></pre></div>

<h5>随机梯度下降算法</h5>
<p>以下的代码使用随机梯度下降算法，其准确率大约为 49%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.49206349206349204</span>
</code></pre></div>

<h5>朴素贝叶斯算法</h5>
<p>以下的代码使用朴素贝叶斯算法，朴素贝叶斯训练模型的准确率大约为 60%。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="mf">0.6009070294784581</span>
</code></pre></div>

<h4>情感分析的最佳算法</h4>
<p>接下来，我们绘制所有算法的准确率图。如下图所示。</p>
<p><img alt="Figure 5: Accuracy performance of the different algorithms" src="/data/attachment/album/202302/03/112300fl2uak20vakxu070.jpg"></p>
<p>可以看到，对于情感分析这一问题，随机森林算法有最佳的准确率。由此，我们可以得出结论，随机森林算法是所有机器算法中最适合情感分析的算法。我们可以通过处理得到更好的特征、尝试其他矢量化技术、或者使用更好的数据集或更好的分类算法，来进一步提高准确率。</p>
<p>既然，随机森林算法是解决情感分析问题的最佳算法，我将向你展示一个预处理数据的样本。在下图中，你可以看到模型会做出正确的预测！试试这个来改进你的项目吧！</p>
<p><img alt="Figure 6: Sample predictions made" src="/data/attachment/album/202302/03/112301vcbt5899c0hcig56.jpg"></p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>