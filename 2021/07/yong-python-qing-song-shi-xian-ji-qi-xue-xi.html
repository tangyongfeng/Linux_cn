<!DOCTYPE html>
<html lang="zh">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>用 Python 轻松实现机器学习</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="Author: Girish Managoli 用朴素贝叶斯分类器解决现实世界里的机器学习问题。 朴素贝叶斯 Naïve Bayes 是一种分类技术，它是许多分类器建模算 …" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">linux_cn</a></h1>
                <nav><ul>
                    <li><a href="/category/chuan-shan-jia-zhuan-fang">穿山甲专访</a></li>
                    <li><a href="/category/dai-ma-ying-xiong">代码英雄</a></li>
                    <li><a href="/category/fen-xiang">分享</a></li>
                    <li><a href="/category/guan-dian">观点</a></li>
                    <li><a href="/category/huo-dong">活动</a></li>
                    <li><a href="/category/ji-ke-man-hua">极客漫画</a></li>
                    <li><a href="/category/ji-zhu">技术</a></li>
                    <li><a href="/category/kai-yuan-zhi-hui">开源智慧</a></li>
                    <li><a href="/category/linux-fa-xing-ban">Linux 发行版</a></li>
                    <li><a href="/category/mei-ri-an-quan-zi-xun">每日安全资讯</a></li>
                    <li><a href="/category/misc">Misc</a></li>
                    <li><a href="/category/qu-kuai-lian">区块链</a></li>
                    <li><a href="/category/rong-qi-yu-yun">容器与云</a></li>
                    <li class="active"><a href="/category/ruan-jian-kai-fa">软件开发</a></li>
                    <li><a href="/category/shu-mei-pai">树莓派</a></li>
                    <li><a href="/category/xi-tong-yun-wei">系统运维</a></li>
                    <li><a href="/category/xin-wen">新闻</a></li>
                    <li><a href="/category/ying-he-guan-cha">硬核观察</a></li>
                    <li><a href="/category/zhi-ye-sheng-ya">职业生涯</a></li>
                    <li><a href="/category/zhong-jiang-ming-dan">中奖名单</a></li>
                    <li><a href="/category/zhuo-mian-ying-yong">桌面应用</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/2021/07/yong-python-qing-song-shi-xian-ji-qi-xue-xi.html" rel="bookmark"
           title="Permalink to 用 Python 轻松实现机器学习">用 Python 轻松实现机器学习</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2021-07-29T10:50:41+02:00">
                Published: Thu 29 July 2021
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/linux-fans-from-china.html">linux fans from china</a>
        </address>
<p>In <a href="/category/ruan-jian-kai-fa">软件开发</a>.</p>

</footer><!-- /.post-info -->      <p>Author: Girish Managoli</p>
<blockquote>
<p>用朴素贝叶斯分类器解决现实世界里的机器学习问题。</p>
</blockquote>
<p><img alt="" src="/data/attachment/album/202107/29/105035ocxdhdob78wmmtzd.jpg" title="arrows cycle symbol for failing faster"></p>
<p><ruby> 朴素贝叶斯 <rt>  Naïve Bayes </rt></ruby>是一种分类技术，它是许多分类器建模算法的基础。基于朴素贝叶斯的分类器是简单、快速和易用的机器学习技术之一，而且在现实世界的应用中很有效。</p>
<p>朴素贝叶斯是从 <ruby> <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">  贝叶斯定理 </a> <rt>  Bayes' theorem </rt></ruby> 发展来的。贝叶斯定理由 18 世纪的统计学家 <a href="https://en.wikipedia.org/wiki/Thomas_Bayes">托马斯·贝叶斯</a> 提出，它根据与一个事件相关联的其他条件来计算该事件发生的概率。比如，<a href="https://en.wikipedia.org/wiki/Parkinson%27s_disease">帕金森氏病</a> 患者通常嗓音会发生变化，因此嗓音变化就是与预测帕金森氏病相关联的症状。贝叶斯定理提供了计算目标事件发生概率的方法，而朴素贝叶斯是对该方法的推广和简化。</p>
<h3>解决一个现实世界里的问题</h3>
<p>这篇文章展示了朴素贝叶斯分类器解决现实世界问题（相对于完整的商业级应用）的能力。我会假设你对机器学习有基本的了解，所以文章里会跳过一些与机器学习预测不大相关的步骤，比如 <ruby> 数据打乱 <rt>  date shuffling </rt></ruby> 和 <ruby> 数据切片 <rt>  data splitting </rt></ruby>。如果你是机器学习方面的新手或者需要一个进修课程，请查看 《<a href="https://opensource.com/article/17/9/introduction-machine-learning">An introduction to machine learning today</a>》 和 《<a href="https://opensource.com/business/15/9/getting-started-open-source-machine-learning">Getting started with open source machine learning</a>》。</p>
<p>朴素贝叶斯分类器是 <ruby> <a href="https://en.wikipedia.org/wiki/Supervised_learning">  有监督的 </a> <rt>  supervised </rt></ruby>、属于 <ruby> <a href="https://en.wikipedia.org/wiki/Generative_model">  生成模型 </a> <rt>  generative </rt></ruby> 的、非线性的、属于 <ruby> <a href="https://en.wikipedia.org/wiki/Parametric_model">  参数模型 </a> <rt>  parametric </rt></ruby> 的和 <ruby> <a href="https://en.wikipedia.org/wiki/Probabilistic_classification">  基于概率的 </a> <rt>  probabilistic </rt></ruby>。</p>
<p>在这篇文章里，我会演示如何用朴素贝叶斯预测帕金森氏病。需要用到的数据集来自 <a href="https://archive.ics.uci.edu/ml/datasets/parkinsons">UCI 机器学习库</a>。这个数据集包含许多语音信号的指标，用于计算患帕金森氏病的可能性；在这个例子里我们将使用这些指标中的前 8 个：</p>
<ul>
<li><strong>MDVP:Fo(Hz)</strong>：平均声带基频</li>
<li><strong>MDVP:Fhi(Hz)</strong>：最高声带基频</li>
<li><strong>MDVP:Flo(Hz)</strong>：最低声带基频</li>
<li><strong>MDVP:Jitter(%)</strong>、<strong>MDVP:Jitter(Abs)</strong>、<strong>MDVP:RAP</strong>、<strong>MDVP:PPQ</strong> 和 <strong>Jitter:DDP</strong>：5 个衡量声带基频变化的指标</li>
</ul>
<p>这个例子里用到的数据集，可以在我的 <a href="https://github.com/gammay/Machine-learning-made-easy-Naive-Bayes/tree/main/parkinsons">GitHub 仓库</a> 里找到。数据集已经事先做了打乱和切片。</p>
<h3>用 Python 实现机器学习</h3>
<p>接下来我会用 Python 来解决这个问题。我用的软件是：</p>
<ul>
<li>Python 3.8.2</li>
<li>Pandas 1.1.1</li>
<li>scikit-learn 0.22.2.post1</li>
</ul>
<p>Python 有多个朴素贝叶斯分类器的实现，都是开源的，包括：</p>
<ul>
<li><strong>NLTK Naïve Bayes</strong>：基于标准的朴素贝叶斯算法，用于文本分类</li>
<li><strong>NLTK Positive Naïve Bayes</strong>：NLTK Naïve Bayes 的变体，用于对只标注了一部分的训练集进行二分类</li>
<li><strong>Scikit-learn Gaussian Naïve Bayes</strong>：提供了部分拟合方法来支持数据流或很大的数据集（LCTT 译注：它们可能无法一次性导入内存，用部分拟合可以动态地增加数据）</li>
<li><strong>Scikit-learn Multinomial Naïve Bayes</strong>：针对离散型特征、实例计数、频率等作了优化</li>
<li><strong>Scikit-learn Bernoulli Naïve Bayes</strong>：用于各个特征都是二元变量/布尔特征的情况</li>
</ul>
<p>在这个例子里我将使用 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html">sklearn Gaussian Naive Bayes</a>。</p>
<p>我的 Python 实现在 <code>naive_bayes_parkinsons.py</code> 里，如下所示：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># x_rows 是我们所使用的 8 个特征的列名</span>
<span class="n">x_rows</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;MDVP:Fo(Hz)&#39;</span><span class="p">,</span><span class="s1">&#39;MDVP:Fhi(Hz)&#39;</span><span class="p">,</span><span class="s1">&#39;MDVP:Flo(Hz)&#39;</span><span class="p">,</span>
        <span class="s1">&#39;MDVP:Jitter(%)&#39;</span><span class="p">,</span><span class="s1">&#39;MDVP:Jitter(Abs)&#39;</span><span class="p">,</span><span class="s1">&#39;MDVP:RAP&#39;</span><span class="p">,</span><span class="s1">&#39;MDVP:PPQ&#39;</span><span class="p">,</span><span class="s1">&#39;Jitter:DDP&#39;</span><span class="p">]</span>
<span class="n">y_rows</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">]</span> <span class="c1"># y_rows 是类别的列名，若患病，值为 1，若不患病，值为 0</span>

<span class="c1"># 训练</span>

<span class="c1"># 读取训练数据</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;parkinsons/Data_Parkinsons_TRAIN.csv&#39;</span><span class="p">)</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">x_rows</span><span class="p">]</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">y_rows</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_x:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">train_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_y:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># 导入 sklearn Gaussian Naive Bayes，然后进行对训练数据进行拟合</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># 对训练数据进行预测</span>
<span class="n">predict_train</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Prediction on train data:&#39;</span><span class="p">,</span> <span class="n">predict_train</span><span class="p">)</span>

<span class="c1"># 在训练数据上的准确率</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">train_y</span><span class="p">,</span> <span class="n">predict_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuray score on train data:&#39;</span><span class="p">,</span> <span class="n">accuracy_train</span><span class="p">)</span>

<span class="c1"># 测试</span>

<span class="c1"># 读取测试数据</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;parkinsons/Data_Parkinsons_TEST.csv&#39;</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">x_rows</span><span class="p">]</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">y_rows</span><span class="p">]</span>

<span class="c1"># 对测试数据进行预测</span>
<span class="n">predict_test</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Prediction on test data:&#39;</span><span class="p">,</span> <span class="n">predict_test</span><span class="p">)</span>

<span class="c1"># 在测试数据上的准确率</span>
<span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">predict_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuray score on test data:&#39;</span><span class="p">,</span> <span class="n">accuracy_train</span><span class="p">)</span>
</code></pre></div>

<p>运行这个 Python 脚本：</p>
<div class="highlight"><pre><span></span><code>$<span class="w"> </span>python<span class="w"> </span>naive_bayes_parkinsons.py

train_x:
<span class="w">      </span>MDVP:Fo<span class="o">(</span>Hz<span class="o">)</span><span class="w">  </span>MDVP:Fhi<span class="o">(</span>Hz<span class="o">)</span><span class="w"> </span>...<span class="w">  </span>MDVP:RAP<span class="w">  </span>MDVP:PPQ<span class="w">  </span>Jitter:DDP
<span class="m">0</span><span class="w">        </span><span class="m">152</span>.125<span class="w">       </span><span class="m">161</span>.469<span class="w">  </span>...<span class="w">   </span><span class="m">0</span>.00191<span class="w">   </span><span class="m">0</span>.00226<span class="w">     </span><span class="m">0</span>.00574
<span class="m">1</span><span class="w">        </span><span class="m">120</span>.080<span class="w">       </span><span class="m">139</span>.710<span class="w">  </span>...<span class="w">   </span><span class="m">0</span>.00180<span class="w">   </span><span class="m">0</span>.00220<span class="w">     </span><span class="m">0</span>.00540
<span class="m">2</span><span class="w">        </span><span class="m">122</span>.400<span class="w">       </span><span class="m">148</span>.650<span class="w">  </span>...<span class="w">   </span><span class="m">0</span>.00465<span class="w">   </span><span class="m">0</span>.00696<span class="w">     </span><span class="m">0</span>.01394
<span class="m">3</span><span class="w">        </span><span class="m">237</span>.323<span class="w">       </span><span class="m">243</span>.709<span class="w">  </span>...<span class="w">   </span><span class="m">0</span>.00173<span class="w">   </span><span class="m">0</span>.00159<span class="w">     </span><span class="m">0</span>.00519
..<span class="w">           </span>...<span class="w">           </span>...<span class="w">           </span>...<span class="w">  </span>...<span class="w">       </span>...<span class="w">       </span>...<span class="w">        </span>
<span class="m">155</span><span class="w">      </span><span class="m">138</span>.190<span class="w">       </span><span class="m">203</span>.522<span class="w">  </span>...<span class="w">   </span><span class="m">0</span>.00406<span class="w">   </span><span class="m">0</span>.00398<span class="w">     </span><span class="m">0</span>.01218

<span class="o">[</span><span class="m">156</span><span class="w"> </span>rows<span class="w"> </span>x<span class="w"> </span><span class="m">8</span><span class="w"> </span>columns<span class="o">]</span>

train_y:
<span class="w">      </span>status
<span class="m">0</span><span class="w">         </span><span class="m">1</span>
<span class="m">1</span><span class="w">         </span><span class="m">1</span>
<span class="m">2</span><span class="w">         </span><span class="m">1</span>
<span class="m">3</span><span class="w">         </span><span class="m">0</span>
..<span class="w">      </span>...
<span class="m">155</span><span class="w">       </span><span class="m">1</span>

<span class="o">[</span><span class="m">156</span><span class="w"> </span>rows<span class="w"> </span>x<span class="w"> </span><span class="m">1</span><span class="w"> </span>columns<span class="o">]</span>

Prediction<span class="w"> </span>on<span class="w"> </span>train<span class="w"> </span>data:<span class="w"> </span><span class="o">[</span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span><span class="w"> </span>...<span class="w"> </span><span class="m">1</span><span class="o">]</span>
Accuracy<span class="w"> </span>score<span class="w"> </span>on<span class="w"> </span>train<span class="w"> </span>data:<span class="w"> </span><span class="m">0</span>.6666666666666666

Prediction<span class="w"> </span>on<span class="w"> </span><span class="nb">test</span><span class="w"> </span>data:<span class="w"> </span><span class="o">[</span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>...<span class="w"> </span><span class="m">1</span>
<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="o">]</span>
Accuracy<span class="w"> </span>score<span class="w"> </span>on<span class="w"> </span><span class="nb">test</span><span class="w"> </span>data:<span class="w"> </span><span class="m">0</span>.6666666666666666
</code></pre></div>

<p>在训练集和测试集上的准确率都是 67%。它的性能还可以进一步优化。你想尝试一下吗？你可以在下面的评论区给出你的方法。</p>
<h3>背后原理</h3>
<p>朴素贝叶斯分类器从贝叶斯定理发展来的。贝叶斯定理用于计算条件概率，或者说贝叶斯定理用于计算当与一个事件相关联的其他事件发生时，该事件发生的概率。简而言之，它解决了这个问题：<em>如果我们已经知道事件 x 发生在事件 y 之前的概率，那么当事件 x 再次发生时，事件 y 发生的概率是多少？</em> 贝叶斯定理用一个先验的预测值来逐渐逼近一个最终的 <a href="https://en.wikipedia.org/wiki/Posterior_probability">后验概率</a>。贝叶斯定理有一个基本假设，就是所有的参数重要性相同（LCTT 译注：即相互独立）。</p>
<p>贝叶斯计算主要包括以下步骤：</p>
<ol>
<li>计算总的先验概率：<br>
P(患病)P(患病) 和 P(不患病)P(不患病)</li>
<li>计算 8 种指标各自是某个值时的后验概率 (value1,...,value8 分别是 MDVP:Fo(Hz)，...，Jitter:DDP 的取值)：<br>
P(value1,\ldots,value8\ |\ 患病)P(value1,…,value8 ∣ 患病)<br>
P(value1,\ldots,value8\ |\ 不患病)P(value1,…,value8 ∣ 不患病)</li>
<li>将第 1 步和第 2 步的结果相乘，最终得到患病和不患病的后验概率：<br>
P(患病\ |\ value1,\ldots,value8) \propto P(患病) \times P(value1,\ldots,value8\ |\ 患病)P(患病 ∣ value1,…,value8)∝P(患病)×P(value1,…,value8 ∣ 患病)<br>
P(不患病\ |\ value1,\ldots,value8) \propto P(不患病) \times P(value1,\ldots,value8\ |\ 不患病)P(不患病 ∣ value1,…,value8)∝P(不患病)×P(value1,…,value8 ∣ 不患病)</li>
</ol>
<p>上面第 2 步的计算非常复杂，朴素贝叶斯将它作了简化：</p>
<ol>
<li>计算总的先验概率：<br>
P(患病)P(患病) 和 P(不患病)P(不患病)</li>
<li>对 8 种指标里的每个指标，计算其取某个值时的后验概率：<br>
P(value1\ |\ 患病),\ldots,P(value8\ |\ 患病)P(value1 ∣ 患病),…,P(value8 ∣ 患病)<br>
P(value1\ |\ 不患病),\ldots,P(value8\ |\ 不患病)P(value1 ∣ 不患病),…,P(value8 ∣ 不患病)</li>
<li>将第 1 步和第 2 步的结果相乘，最终得到患病和不患病的后验概率：<br>
P(患病\ |\ value1,\ldots,value8) \propto P(患病) \times P(value1\ |\ 患病) \times \ldots \times P(value8\ |\ 患病)P(患病 ∣ value1,…,value8)∝P(患病)×P(value1 ∣ 患病)×…×P(value8 ∣ 患病)<br>
P(不患病\ |\ value1,\ldots,value8) \propto P(不患病) \times P(value1\ |\ 不患病) \times \ldots \times P(value8\ |\ 不患病)P(不患病 ∣ value1,…,value8)∝P(不患病)×P(value1 ∣ 不患病)×…×P(value8 ∣ 不患病)</li>
</ol>
<p>这只是一个很初步的解释，还有很多其他因素需要考虑，比如数据类型的差异，稀疏数据，数据可能有缺失值等。</p>
<h3>超参数</h3>
<p>朴素贝叶斯作为一个简单直接的算法，不需要超参数。然而，有的版本的朴素贝叶斯实现可能提供一些高级特性（比如超参数）。比如，<a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html">GaussianNB</a> 就有 2 个超参数：</p>
<ul>
<li><strong>priors</strong>：先验概率，可以事先指定，这样就不必让算法从数据中计算才能得出。</li>
<li><strong>var_smoothing</strong>：考虑数据的分布情况，当数据不满足标准的高斯分布时，这个超参数会发挥作用。</li>
</ul>
<h3>损失函数</h3>
<p>为了坚持简单的原则，朴素贝叶斯使用 <a href="https://en.wikipedia.org/wiki/Loss_function#0-1_loss_function">0-1 损失函数</a>。如果预测结果与期望的输出相匹配，损失值为 0，否则为 1。</p>
<h3>优缺点</h3>
<p><strong>优点</strong>：朴素贝叶斯是最简单、最快速的算法之一。<br>
<strong>优点</strong>：在数据量较少时，用朴素贝叶斯仍可作出可靠的预测。<br>
<strong>缺点</strong>：朴素贝叶斯的预测只是估计值，并不准确。它胜在速度而不是准确度。<br>
<strong>缺点</strong>：朴素贝叶斯有一个基本假设，就是所有特征相互独立，但现实情况并不总是如此。</p>
<p>从本质上说，朴素贝叶斯是贝叶斯定理的推广。它是最简单最快速的机器学习算法之一，用来进行简单和快速的训练和预测。朴素贝叶斯提供了足够好、比较准确的预测。朴素贝叶斯假设预测特征之间是相互独立的。已经有许多朴素贝叶斯的开源的实现，它们的特性甚至超过了贝叶斯算法的实现。</p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>