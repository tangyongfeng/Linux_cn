<!DOCTYPE html>
<html lang="zh">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="Author: nido 这是一款提取网站数据的开源工具。Scrapy框架用Python开发而成，它使抓取工作又快又简单，且可扩展。我们已经在virtual box中创建一台虚拟机（VM）并且在上面安装了Ubuntu …" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">linux_cn</a></h1>
                <nav><ul>
                    <li><a href="/category/chuan-shan-jia-zhuan-fang">穿山甲专访</a></li>
                    <li><a href="/category/dai-ma-ying-xiong">代码英雄</a></li>
                    <li><a href="/category/fen-xiang">分享</a></li>
                    <li><a href="/category/guan-dian">观点</a></li>
                    <li><a href="/category/huo-dong">活动</a></li>
                    <li><a href="/category/ji-ke-man-hua">极客漫画</a></li>
                    <li class="active"><a href="/category/ji-zhu">技术</a></li>
                    <li><a href="/category/kai-yuan-zhi-hui">开源智慧</a></li>
                    <li><a href="/category/linux-fa-xing-ban">Linux 发行版</a></li>
                    <li><a href="/category/mei-ri-an-quan-zi-xun">每日安全资讯</a></li>
                    <li><a href="/category/misc">Misc</a></li>
                    <li><a href="/category/qu-kuai-lian">区块链</a></li>
                    <li><a href="/category/rong-qi-yu-yun">容器与云</a></li>
                    <li><a href="/category/ruan-jian-kai-fa">软件开发</a></li>
                    <li><a href="/category/shu-mei-pai">树莓派</a></li>
                    <li><a href="/category/xi-tong-yun-wei">系统运维</a></li>
                    <li><a href="/category/xin-wen">新闻</a></li>
                    <li><a href="/category/ying-he-guan-cha">硬核观察</a></li>
                    <li><a href="/category/zhi-ye-sheng-ya">职业生涯</a></li>
                    <li><a href="/category/zhong-jiang-ming-dan">中奖名单</a></li>
                    <li><a href="/category/zhuo-mian-ying-yong">桌面应用</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/2015/03/ru-he-zai-ubuntu-1404-ltsan-zhuang-wang-luo-pa-chong-gong-ju-scrapy.html" rel="bookmark"
           title="Permalink to 如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy">如何在Ubuntu 14.04 LTS安装网络爬虫工具：Scrapy</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2015-03-21T17:42:00+01:00">
                Published: Sat 21 March 2015
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/linux-fans-from-china.html">linux fans from china</a>
        </address>
<p>In <a href="/category/ji-zhu">技术</a>.</p>

</footer><!-- /.post-info -->      <p>Author: nido</p>
<p>这是一款提取网站数据的开源工具。Scrapy框架用Python开发而成，它使抓取工作又快又简单，且可扩展。我们已经在virtual box中创建一台虚拟机（VM）并且在上面安装了Ubuntu 14.04 LTS。</p>
<h3>安装 Scrapy</h3>
<p><img alt="" src="/data/attachment/album/201503/21/174213pc6aqwfzf81qnzga.jpg"></p>
<p>Scrapy依赖于Python、开发库和pip。Python最新的版本已经在Ubuntu上预装了。因此我们在安装Scrapy之前只需安装pip和python开发库就可以了。</p>
<p>pip是作为python包索引器easy_install的替代品，用于安装和管理Python包。pip包的安装可见图 1。</p>
<div class="highlight"><pre><span></span><code>sudo apt-get install python-pip
</code></pre></div>

<p><img alt="Fig:1 Pip installation" src="/data/attachment/album/201503/21/174230mh16gvlvhzzl6urt.png"></p>
<p><em>图:1 pip安装</em></p>
<p>我们必须要用下面的命令安装python开发库。如果包没有安装那么就会在安装scrapy框架的时候报关于python.h头文件的错误。</p>
<div class="highlight"><pre><span></span><code>sudo apt-get install python-dev
</code></pre></div>

<p><img alt="Fig:2 Python Developer Libraries" src="/data/attachment/album/201503/21/174231qahzo63dabnbaby8.png"></p>
<p><em>图:2 Python 开发库</em></p>
<p>scrapy框架既可从deb包安装也可以从源码安装。在图3中我们用pip（Python 包管理器）安装了deb包了。</p>
<div class="highlight"><pre><span></span><code>sudo pip install scrapy 
</code></pre></div>

<p><img alt="Fig:3 Scrapy Installation" src="/data/attachment/album/201503/21/174232nb8xy0ylvzb5umnt.png"></p>
<p><em>图:3 Scrapy 安装</em></p>
<p>图4中scrapy的成功安装需要一些时间。</p>
<p><img alt="Fig:4 Successful installation of Scrapy Framework" src="/data/attachment/album/201503/21/174234aczsnbic07gsngss.png"></p>
<p><em>图:4 成功安装Scrapy框架</em></p>
<h3>使用scrapy框架提取数据</h3>
<h4>基础教程</h4>
<p>我们将用scrapy从fatwallet.com上提取商店名称（卖卡的店）。首先，我们使用下面的命令新建一个scrapy项目“store name”， 见图5。</p>
<div class="highlight"><pre><span></span><code>$sudo scrapy startproject store_name
</code></pre></div>

<p><img alt="Fig:5 Creation of new project in Scrapy Framework" src="/data/attachment/album/201503/21/174237ldhdytd10yg44hyh.png"></p>
<p><em>图:5 Scrapy框架新建项目</em></p>
<p>上面的命令在当前路径创建了一个“store_name”的目录。项目主目录下包含的文件/文件夹见图6。</p>
<div class="highlight"><pre><span></span><code>$sudo ls –lR store_name
</code></pre></div>

<p><img alt="Fig:6 Contents of store_name project." src="/data/attachment/album/201503/21/174240dhzs3aa7df3s0shu.png"></p>
<p><em>图:6 store_name项目的内容</em></p>
<p>每个文件/文件夹的概要如下：</p>
<ul>
<li>scrapy.cfg 是项目配置文件</li>
<li>store_name/ 主目录下的另一个文件夹。 这个目录包含了项目的python代码</li>
<li>store_name/items.py 包含了将由蜘蛛爬取的项目</li>
<li>store_name/pipelines.py 是管道文件</li>
<li>store_name/settings.py 是项目的配置文件</li>
<li>store_name/spiders/， 包含了用于爬取的蜘蛛</li>
</ul>
<p>由于我们要从fatwallet.com上如提取店名，因此我们如下修改文件（LCTT 译注：这里没说明是哪个文件，译者认为应该是 items.py）。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">StoreNameItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>

   <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>   <span class="c1">#  取出卡片商店的名称</span>
</code></pre></div>

<p>之后我们要在项目的store_name/spiders/文件夹下写一个新的蜘蛛。蜘蛛是一个python类，它包含了下面几个必须的属性：</p>
<ol>
<li>蜘蛛名 (name )</li>
<li>爬取起点url (start_urls)</li>
<li>包含了从响应中提取需要内容相应的正则表达式的解析方法。解析方法对爬虫而言很重要。</li>
</ol>
<p>我们在store<em>name/spiders/目录下创建了“store</em>name.py”爬虫，并添加如下的代码来从fatwallet.com上提取店名。爬虫的输出写到文件（<strong>StoreName.txt</strong>）中，见图7。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
<span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">FormRequest</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="k">class</span> <span class="nc">StoreNameItem</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
<span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;storename&quot;</span>
<span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fatwallet.com&quot;</span><span class="p">]</span>
<span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;http://fatwallet.com/cash-back-shopping/&quot;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">response</span><span class="p">):</span>
<span class="n">output</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;StoreName.txt&#39;</span><span class="p">,</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

<span class="n">tags</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//tr[@class=&quot;storeListRow&quot;]|</span><span class="se">\</span>
<span class="s1">         //tr[@class=&quot;storeListRow even&quot;]|</span><span class="se">\</span>
<span class="s1">         //tr[@class=&quot;storeListRow even last&quot;]|</span><span class="se">\</span>
<span class="s1">          //tr[@class=&quot;storeListRow last&quot;]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="s1">&#39;ignore&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
<span class="n">store_name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;class=</span><span class="se">\&quot;</span><span class="s2">storeListStoreName</span><span class="se">\&quot;</span><span class="s2">&gt;.*?&lt;&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="o">|</span><span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">):</span>
<span class="n">store_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;class=</span><span class="se">\&quot;</span><span class="s2">storeListStoreName</span><span class="se">\&quot;</span><span class="s2">&gt;.*?&lt;&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="o">|</span><span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">()</span>
<span class="n">store_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&gt;.*?&lt;&quot;</span><span class="p">,</span><span class="n">store_name</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="o">|</span><span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">()</span>
<span class="n">store_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&gt;&#39;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&lt;&#39;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">store_name</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="p">))</span>
<span class="n">store_name</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&amp;amp;&#39;</span><span class="p">,</span><span class="s2">&quot;&amp;&quot;</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&amp;amp;&#39;</span><span class="p">,</span><span class="s2">&quot;&amp;&quot;</span><span class="p">,</span><span class="n">store_name</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="p">))</span>
<span class="c1">#print store_name</span>
<span class="n">output</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">store_name</span><span class="o">+</span><span class="s2">&quot;&quot;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><img alt="Fig:7 Output of the Spider code ." src="/data/attachment/album/201503/21/174242z4g4b5bxg4p9s4ga.png"></p>
<p><em>图:7 爬虫的输出</em></p>
<p><em>注意: 本教程的目的仅用于理解scrapy框架</em></p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>